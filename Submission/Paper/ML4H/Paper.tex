 % use the "wcp" class option for workshop and conference
 % proceedings
 %\documentclass[gray]{jmlr} % test grayscale version
 %\documentclass[tablecaption=bottom]{jmlr}% journal article
 \documentclass[pmlr,twocolumn,10pt]{jmlr} % W&CP article

% \usepackage{geometry}
% \geometry{margins=0.1in,textwidth=7in}

 % The following packages will be automatically loaded:
 % amsmath, amssymb, natbib, graphicx, url, algorithm2e

 %\usepackage{rotating}% for sideways figures and tables
 %\usepackage{longtable}% for long tables

 % The booktabs package is used by this sample document
 % (it provides \toprule, \midrule and \bottomrule).
 % Remove the next line if you don't require it.
\usepackage{tabto}    
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{url}

\usepackage{booktabs}
 % The siunitx package is used by this sample document
 % to align numbers in a column by their decimal point.
 % Remove the next line if you don't require it.
\usepackage[load-configurations=version-1]{siunitx} % newer version 
%\usepackage{siunitx}

 % The following command is just for this sample document:
\newcommand{\cs}[1]{\texttt{\char`\\#1}}% remove this in your real article

% The following is to recognise equal contribution for authorship
\newcommand{\equal}[1]{{\hypersetup{linkcolor=black}\thanks{#1}}}

% Customized Tabs
\newcommand\mytab{\tab \hspace{-5cm}}

 % Define an unnumbered theorem just for this sample document for
 % illustrative purposes:
\theorembodyfont{\upshape}
\theoremheaderfont{\scshape}
\theorempostheader{:}
\theoremsep{\newline}
\newtheorem*{note}{Note}

 % change the arguments, as appropriate, in the following:
\jmlrvolume{LEAVE UNSET}
\jmlryear{2021}
\jmlrsubmitted{LEAVE UNSET}
\jmlrpublished{LEAVE UNSET}
\jmlrworkshop{Machine Learning for Health (ML4H) 2021} % W&CP title

 % The optional argument of \title is used in the header
\title[Short Title]{Full Title of Article\titlebreak This Title Has
A Line Break}

 % Anything in the title that should appear in the main title but 
 % not in the article's header or the volume's table of
 % contents should be placed inside \titletag{}

 %\title{Title of the Article\titletag{\thanks{Some footnote}}}


 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % \thanks must come after \Name{...} not inside the argument for
 % example \Name{John Smith}\nametag{\thanks{A note}} NOT \Name{John
 % Smith\thanks{A note}}

 % Anything in the name that should appear in the title but not in the 
 % article's header or footer or in the volume's
 % table of contents should be placed inside \nametag{}

 % Two authors with the same address
 % \author{%
 %  \Name{Author Name1\nametag{\thanks{A note}}} \Email{abc@sample.com}\and
 %  \Name{Author Name2} \Email{xyz@sample.com}\\
 %  \addr Address
 % }

 % Three or more authors with the same address:
 % \author{%
 %  \Name{Author Name1} \Email{an1@sample.com}\\
 %  \Name{Author Name2} \Email{an2@sample.com}\\
 %  \Name{Author Name3} \Email{an3@sample.com}\\
 %  \Name{Author Name4} \Email{an4@sample.com}\\
 %  \Name{Author Name5} \Email{an5@sample.com}\\
 %  \Name{Author Name6} \Email{an6@sample.com}\\
 %  \Name{Author Name7} \Email{an7@sample.com}\\
 %  \Name{Author Name8} \Email{an8@sample.com}\\
 %  \Name{Author Name9} \Email{an9@sample.com}\\
 %  \Name{Author Name10} \Email{an10@sample.com}\\
 %  \Name{Author Name11} \Email{an11@sample.com}\\
 %  \Name{Author Name12} \Email{an12@sample.com}\\
 %  \Name{Author Name13} \Email{an13@sample.com}\\
 %  \Name{Author Name14} \Email{an14@sample.com}\\
 %  \addr Address
 % }

 % Authors with different addresses and equal first authors:
\author{%
\Name{First Author 1}\equal{These authors contributed equally} \Email{abc@sample.com}\\
\addr University X, Country 1
\AND
% footnotemark[1] is to refer to the \equal footnote
\Name{First Author 2}\footnotemark[1] \Email{def@sample.com}\\
\addr University Y, Country 2
\AND
\Name{Last Author} \Email{ghi@sample.com}\\
\addr University Z, Country 3
}

\begin{document}

\maketitle

\begin{abstract}
\tab Dementia is a neurodegenerative disorder that causes cognitive decline and affects more than 50 million people worldwide. Dementia is under-diagnosed by healthcare professionals—only one in four people who suffer from dementia are diagnosed. Even when a diagnosis is made, it may not be entered as a structured diagnosis code in a patient’s charts.  Information relevant to cognitive impairment is often found within electronic health records but manual review of clinician notes by experts is both time consuming and often prone to errors. Automated evaluation of these notes presents an opportunity to label patients with cognitive impairment (CI) in real-world data. 
\end{abstract}
\begin{keywords}
EHR, NLP, Demetia
\end{keywords}

\section{Introduction}
\label{sec:intro}

\section{Related Works}
\label{sec:RelatedWorks}

\section{Dataset, Preprocessing, and Annotations}

\paragraph{Dataset}
\label{sec:Dataset} Our gold-standard dataset consisted of a cohort (N = 16,428) of patients from the Mass General Brigham (MGB) HealthCare (formerly Partner's Healthcare, comprising two major academic hospitals, community hospitals, and community health centers in the Boston area) system who were older than 60 years (as of July 13, 2021) and had APOE genotype data available from the BioBank. Each patients' EHR record was then annotated by neurologists using a web-based annotation tool (UI Interface in Appendix A) as 1) Yes, i.e., patient has CI; 2) No i.e., Patient does not have CI; and 3) Neither i.e., sequence has no information on patient’s cognition.

\paragraph{Preprocessing}
\label{sec:Preprocessing} For each patient in our gold-standard dataset, we extracted unstructured clinician notes, identified matches to dementia-related keywords (listed in Table 1), and constructed 800 character sequences from the note text around each of these matches. Our cohort of 16,428 patients had 279,224 sequences in total. 

\begin{table*}[htbp]
\floatconts
  {tab:operatornames}
  {\caption{Keywords indicative of Cognitive Impairment}}%
    {
        \begin{tabular}{lcc}
            \toprule
            \bfseries Keyword & \bfseries Match Count \\
            \midrule    
        
            \textbf{Memory} & \fseries 109218 \\ 
            \textbf{Cognition}  & \fseries 87655 \\ 
            \textbf{Dementia} & \fseries 51034 \\ 
            \textbf{Cerebral} & \fseries 45886 \\ 
            \textbf{Cerebrovascular} & \fseries 36370 \\ 
            \textbf{Cerebellar} & \fseries 26863 \\
            \textbf{Cognitive Impairment} & \fseries 20267 \\ 
            \textbf{Alzheimer} & \fseries 20581 \\ 
            \textbf{MOCA} & \fseries 9767 \\ 
            \textbf{Neurocognitive} & \fseries 7711 \\ 
            \textbf{MCI} & \fseries 3889 \\ 
            \textbf{Amnesia} & \fseries 3695 \\ 
            \textbf{AD} & \fseries 2673 \\ 
            \textbf{Lewy} & \fseries 2561 \\ 
            \textbf{MMSE} & \fseries 2134 \\ 
            \textbf{LBD} & \fseries 224 \\ 
            \textbf{Corticobasal} & \fseries 147 \\ 
            \textbf{Pick's} & \fseries 41 \\ 
            
            \bottomrule
        \end{tabular}
    }
\end{table*}

\paragraph{Annotations}
\label{sec:Annotations} We initially assigned 5,000 sequences diversified by keyword matches from 5,000 unique patients for neurologist labeling. As the manual annotation of 279,000+ sequences in not feasible, we devised a scheme to expedite annotations known as "always patterns". An always pattern is defined as a phrase or regex expression that in any context indicates the phrase will be labeled with a particular class (i.e. yes, no, or neither). If an always pattern is inputted, all other sequences have language that matches with the phrase will be automatically labeled accordingly. % {List any other sequence assignment schemes} %
Currently, 8,656 sequences have been annotated, 8,050 through always patterns and 606 manually. % {Will change} %

The final dataset was split between train (95\%) and holdout test (5\%) sets, stratified across label and proportion of sequences annotated manually and through always patterns. % {Will change} % 
Validation datasets were split from the train set using techniques described in the Methodology section. Table 2 shows demographics of the cohort of patients.  
\section{Methodology}
\label{sec:Methodology}  

We built 4 models and compared performance to the baseline model. It is important to note that these models were trained on binary labels, despite annotators labeling sequences with 3 classes. This was done because our overall task was to classify if a patient had CI, not whether a sequence indicates CI. This means that a label of neither is not relevant, as a patient can only be classified as having or not having CI. In order to convert this problem to binary labels, we aggregated no and neither labels to class 0 and yes labels to class 1. 

\label{sec:Baseline}  
\paragraph{(1) Baseline Model} We performed L1 regularized logistic regression where the cognitive concern label was regressed on the counts of medications, keyword counts, and ICD codes relevant to CI. The lambda value was selected through 10-fold Cross Validation (CV) to maximize the average area under the Receiver Operator Characteristic (ROC). % {To be implemented} %

\label{sec:TFIDF}  
\paragraph{(2) Logistic Regression with TF-IDF Vectors} We performed TF-IDF (term frequency-inverse document frequency) vectorization on the annotated sequences and selected features based on a term's Pearson correlation coefficient with the outcome. L1 Regularized logistic regression was applied with the annotated cognitive impairment labels. We used different correlation coefficients as thresholds to select features and iterated over different lambda values to determine the optimal lambda value and correlation coefficient threshold. 

\label{sec:BaselineTFIDF}  
\paragraph{(3) Model 1 + Model 2} % {TBD} % 

\label{sec:Transformer}  
\paragraph{(4) Transformer Based Sequence Classification Language Model} % {To be implemented} %

\section{Results}
\label{sec:Results}  

\end{document}
