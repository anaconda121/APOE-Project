{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "import os\n",
    "import sys\n",
    "from datetime import date\n",
    "current_date = date.today()\n",
    "#%load_ext autotime\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib_venn import venn2, venn3\n",
    "import warnings\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "from more_itertools import unique_everseen\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#import pandasql as ps\n",
    "import seaborn as sns\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = pd.read_csv(r\"keywords.csv\") #(r\"regex.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "k = regex[\"REGEX\"].to_list()\n",
    "c = regex[\"CASE\"].to_list()\n",
    "p_list = []\n",
    "\n",
    "for i in range(len(k)):\n",
    "    if (c[i] == \"case\"):\n",
    "        p_list.append(re.compile(k[i]))\n",
    "    else:\n",
    "        p_list.append(re.compile(k[i], re.IGNORECASE))\n",
    "print(len(p_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = pd.read_csv(r\"C:\\users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Bert\\john_hsu_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu[john_hsu[\"NoteTXT\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 387088/387088 [1:20:58<00:00, 79.68it/s]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for note in tqdm(john_hsu[\"NoteTXT\"]):\n",
    "    curr = []\n",
    "    for p in (p_list):\n",
    "        m = list(set(re.findall(p, note)))\n",
    "        m = list(set(map(str.lower, m)))\n",
    "        if (m != []):\n",
    "            curr.append(\"\".join(m))\n",
    "    l.append(str(curr))\n",
    "    \n",
    "john_hsu[\"regex_matches\"] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu[john_hsu[\"regex_matches\"] != \"[]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 99334/99334 [53:51<00:00, 30.74it/s]\n"
     ]
    }
   ],
   "source": [
    "locations = []\n",
    "for r in tqdm(john_hsu['NoteTXT']):\n",
    "    curr_loc = []\n",
    "    for p in p_list:\n",
    "         for match in re.finditer(p ,r):\n",
    "            curr_loc.append(match.span())\n",
    "            \n",
    "    if (curr_loc == []):\n",
    "        print(\"STOP\")\n",
    "        break\n",
    "    locations.append(curr_loc)\n",
    "    \n",
    "john_hsu[\"regex_location\"] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu_sequences = pd.DataFrame(columns = john_hsu.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 99334/99334 [9:30:50<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(john_hsu[\"regex_location\"]))):\n",
    "    curr_sequences = pd.DataFrame(columns = john_hsu.columns)\n",
    "    \n",
    "    #multiple matches per note, decompose list of tuples\n",
    "    if (len(john_hsu[\"regex_location\"][i]) > 1):\n",
    "        for j in range(len(john_hsu[\"regex_location\"][i])):\n",
    "            #print((john_hsu[\"regex_location\"][i][j][0], john_hsu[\"regex_location\"][i][j][1]))\n",
    "            new_regex_location = list((john_hsu[\"regex_location\"][i][j][0], john_hsu[\"regex_location\"][i][j][1]))\n",
    "            #print(new_regex_location, \"0: \", new_regex_location[0], \"1: \", new_regex_location[1])\n",
    "            keyword = john_hsu[\"NoteTXT\"][i][new_regex_location[0] : new_regex_location[1]]\n",
    "            \n",
    "            curr_sequences = curr_sequences.append(john_hsu.loc[i])\n",
    "            curr_sequences = curr_sequences.reset_index(drop = True)\n",
    "            curr_sequences.at[j, \"regex_matches\"] = keyword\n",
    "            curr_sequences.at[j, \"regex_location\"] = new_regex_location\n",
    "    else:\n",
    "        # print(john_hsu[\"regex_location\"][i][0][0], i)\n",
    "        new_regex_location = list((john_hsu[\"regex_location\"][i][0][0], john_hsu[\"regex_location\"][i][0][1]))\n",
    "        keyword = john_hsu[\"NoteTXT\"][i][new_regex_location[0] : new_regex_location[1]]\n",
    "        curr_sequences = curr_sequences.append(john_hsu.loc[i])\n",
    "        curr_sequences = curr_sequences.reset_index(drop = True)\n",
    "        curr_sequences.at[0, \"regex_matches\"] = keyword\n",
    "        curr_sequences.at[0, \"regex_location\"] = new_regex_location\n",
    "    \n",
    "    john_hsu_sequences = john_hsu_sequences.append(curr_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu_sequences = john_hsu_sequences.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 448818/448818 [00:17<00:00, 25417.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(john_hsu_sequences))):\n",
    "    start = john_hsu_sequences[\"regex_location\"][i][0]\n",
    "    end = john_hsu_sequences[\"regex_location\"][i][1]\n",
    "    \n",
    "    prune_start = False\n",
    "    prune_end = False\n",
    "    if (start - 600 <= 0):\n",
    "        start = 0\n",
    "        prune_start = True\n",
    "    if (end + 600 >= len(john_hsu_sequences[\"NoteTXT\"]) - 1):\n",
    "        end = len(john_hsu_sequences[\"NoteTXT\"]) - 1\n",
    "        prune_end = True\n",
    "    \n",
    "    sequence = \"\"\n",
    "    if (prune_start and prune_end):\n",
    "        sequence = john_hsu_sequences[\"NoteTXT\"][i][start : end]\n",
    "    else:\n",
    "        if (prune_start):\n",
    "            sequence = john_hsu_sequences[\"NoteTXT\"][i][start : end + 600]\n",
    "        if (prune_end):\n",
    "            sequence = john_hsu_sequences[\"NoteTXT\"][i][start - 600: end]\n",
    "    \n",
    "    if (not prune_start and not prune_end):\n",
    "        sequence = john_hsu_sequences[\"NoteTXT\"][i][start - 600: end + 600]\n",
    "        \n",
    "    if (sequence == \"\"):\n",
    "        print(\"STOP\", start, end, i, prune_start, prune_end)\n",
    "        break\n",
    "    \n",
    "    john_hsu_sequences.at[i, \"regex_sent\"] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu_sequences = john_hsu_sequences.drop(columns = [\"NoteTXT_Preprocessed\", \"sequence_count\", \"sequence_length\", \"regex_sent_preprocessed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes['regex_match'] = notes['regex_match'].astype(str)\n",
    "notes['regex_match'] = notes['regex_match'].str.replace(\"\\[\\]\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu['regex_sent'] = john_hsu['regex_sent'].astype(str)\n",
    "john_hsu['regex_sent'] = john_hsu['regex_sent'].str.replace('[', '')\n",
    "john_hsu['regex_sent'] = john_hsu['regex_sent'].str.replace(']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu[john_hsu['regex_sent'].notna()]\n",
    "john_hsu['regex_sent'] = john_hsu['regex_sent'].str.replace('\"', \"'\")\n",
    "john_hsu = (john_hsu.assign(regex_sent = john_hsu['regex_sent'].str.split(\"', '\"))\n",
    "         .explode('regex_sent')\n",
    "         .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_preprocessing(note):\n",
    "    note = re.sub(r'   • ', ' ; ', note)\n",
    "    note = re.sub(r'[ ]{4,}', ' ', note)\n",
    "    note = re.sub(r'  ', '\\n', note)\n",
    "    note = re.sub(r'    ', '\\n\\n', note)\n",
    "    return note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 448818/448818 [00:27<00:00, 16247.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(john_hsu_sequences))):\n",
    "    john_hsu_sequences.at[i, \"regex_sent_preprocessed\"] = note_preprocessing(john_hsu_sequences.at[i, \"regex_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu_sequences[\"sequence_length\"] = john_hsu_sequences['regex_sent_preprocessed'].astype(str).map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu_sequences.to_csv(r\"Matches/john_hsu_dataset_matches.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu_sequences[:1000].to_csv(r\"Matches/john_hsu_dataset_1000.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
