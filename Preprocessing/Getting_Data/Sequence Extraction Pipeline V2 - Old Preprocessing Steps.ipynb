{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "import os\n",
    "import sys\n",
    "from datetime import date\n",
    "current_date = date.today()\n",
    "#%load_ext autotime\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib_venn import venn2, venn3\n",
    "import warnings\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "from more_itertools import unique_everseen\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#import pandasql as ps\n",
    "import seaborn as sns\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = pd.read_csv(r\"keywords.csv\") #(r\"regex.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "k = regex[\"REGEX\"].to_list()\n",
    "c = regex[\"CASE\"].to_list()\n",
    "p_list = []\n",
    "\n",
    "for i in range(len(k)):\n",
    "    if (c[i] == \"case\"):\n",
    "        p_list.append(re.compile(k[i]))\n",
    "    else:\n",
    "        p_list.append(re.compile(k[i], re.IGNORECASE))\n",
    "print(len(p_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = pd.read_csv(r\"C:\\users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Bert\\john_hsu_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu[john_hsu[\"NoteTXT\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 387088/387088 [16:43<00:00, 385.86it/s]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for note in tqdm(john_hsu[\"NoteTXT\"]):\n",
    "    curr = []\n",
    "    for p in (p_list):\n",
    "        m = list(set(re.findall(p, note)))\n",
    "        m = list(set(map(str.lower, m)))\n",
    "        if (m != []):\n",
    "            curr.append(\"\".join(m))\n",
    "    l.append(str(curr))\n",
    "    \n",
    "john_hsu[\"regex_matches\"] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu[john_hsu[\"regex_matches\"] != \"[]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 46650/46650 [06:04<00:00, 127.99it/s]\n"
     ]
    }
   ],
   "source": [
    "locations = []\n",
    "for r in tqdm(john_hsu['NoteTXT']):\n",
    "    curr_loc = []\n",
    "    for p in p_list:\n",
    "         for match in re.finditer(p ,r):\n",
    "            curr_loc.append(match.span())\n",
    "            \n",
    "    if (curr_loc == []):\n",
    "        print(\"STOP\")\n",
    "        break\n",
    "    locations.append(curr_loc)\n",
    "    \n",
    "john_hsu[\"regex_location\"] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_windows(i):\n",
    "    merged = []\n",
    "    context_length_one_direction = 100\n",
    "    \n",
    "    for j in range(len(john_hsu[\"regex_location\"][i])):\n",
    "        start = john_hsu[\"regex_location\"][i][j][0]\n",
    "        end = john_hsu[\"regex_location\"][i][j][1]\n",
    "    \n",
    "        prune_start = False\n",
    "        prune_end = False\n",
    "        if (start - context_length_one_direction <= 0):\n",
    "            start = 0\n",
    "            prune_start = True\n",
    "        if (end + context_length_one_direction >= len(john_hsu[\"NoteTXT\"]) - 1):\n",
    "            end = len(john_hsu[\"NoteTXT\"]) - 1\n",
    "            prune_end = True\n",
    "\n",
    "        if (prune_start and prune_end):\n",
    "            merged.append((start, end))\n",
    "        else:\n",
    "            if (prune_start):\n",
    "                merged.append((start, end + context_length_one_direction))\n",
    "            if (prune_end):\n",
    "                merged.append((start - context_length_one_direction, end))\n",
    "\n",
    "        if (not prune_start and not prune_end):\n",
    "            merged.append((start - context_length_one_direction, end + context_length_one_direction))\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 46700/46700 [00:03<00:00, 14640.43it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_locs = []\n",
    "for i in tqdm(range(len(john_hsu))):\n",
    "     merged_locs.append(create_context_windows(i))\n",
    "\n",
    "john_hsu[\"merged_row_location\"] = merged_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(intervals):  \n",
    "    ans = []\n",
    "    i = 1\n",
    "    intervals.sort()\n",
    "    tempans = intervals[0]\n",
    "    \n",
    "    while i < len(intervals):\n",
    "        #check intersection point\n",
    "        if tempans[0] <= intervals[i][1] and tempans[1] >= intervals[i][0]:\n",
    "            newtempans = [min(tempans[0] , intervals[i][0]) , max(tempans[1] , intervals[i][1])]\n",
    "            tempans = newtempans\n",
    "            i += 1\n",
    "        else:\n",
    "            ans.append(tempans)\n",
    "            tempans = intervals[i]\n",
    "            i += 1\n",
    "            \n",
    "    ans.append(tempans)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 46700/46700 [00:00<00:00, 60573.26it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_locs = []\n",
    "for i in tqdm(range(len(john_hsu))):\n",
    "     merged_locs.append(merge(john_hsu[\"merged_row_location\"][i]))\n",
    "\n",
    "john_hsu[\"merged_row_location\"] = merged_locs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_context_windows(i, col):\n",
    "    sequence = \"\"\n",
    "    \n",
    "    for j in range(len(john_hsu[col][i])):\n",
    "        if j > 0 and sequence != \"\":\n",
    "            sequence += \" ----- \"\n",
    "            \n",
    "        start = john_hsu[col][i][j][0]\n",
    "        end = john_hsu[col][i][j][1]\n",
    "        \n",
    "        sequence += john_hsu[\"NoteTXT\"][i][start : end]\n",
    "    \n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 46700/46700 [00:02<00:00, 18045.67it/s]\n"
     ]
    }
   ],
   "source": [
    "seqs = []\n",
    "\n",
    "for i in tqdm(range(len(john_hsu))):\n",
    "    seqs.append(pull_context_windows(i, \"merged_row_location\"))\n",
    "\n",
    "john_hsu[\"regex_sent\"] = seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 46700/46700 [00:37<00:00, 1244.89it/s]\n"
     ]
    }
   ],
   "source": [
    "john_hsu[\"padded_merged_regex_location\"] = john_hsu[\"merged_row_location\"].copy()\n",
    "\n",
    "for i in tqdm(range(len(john_hsu))):\n",
    "    john_hsu[\"padded_merged_regex_location\"][i] = list(eval(john_hsu[\"padded_merged_regex_location\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_context_windows(i):\n",
    "    if (john_hsu[\"token_length\"][i] <= 400):\n",
    "        locs = list(eval(john_hsu[\"merged_row_location\"][i]))\n",
    "        length = len(locs)\n",
    "        start = locs[0][0] \n",
    "        end = locs[length - 1][1]\n",
    "        \n",
    "        #print(start, end)\n",
    "                \n",
    "        seq_length = 1000\n",
    "        length_to_add_one_side = int((seq_length - john_hsu[\"sequence_length\"][i]) / 2)\n",
    "        \n",
    "        # print(length_to_add_one_side, john_hsu[\"sequence_length\"][i])\n",
    "        \n",
    "        prune_start = False\n",
    "        prune_end = False\n",
    "        if (start - length_to_add_one_side <= 0):\n",
    "            start = 0\n",
    "            prune_start = True\n",
    "        if (end + length_to_add_one_side >= len(john_hsu[\"NoteTXT\"]) - 1):\n",
    "            end = len(john_hsu[\"NoteTXT\"]) - 1\n",
    "            prune_end = True\n",
    "            \n",
    "        # print(prune_start, prune_end)\n",
    "\n",
    "        if (prune_start):\n",
    "            end += length_to_add_one_side\n",
    "            if (end + length_to_add_one_side <= len(john_hsu[\"NoteTXT\"])):\n",
    "                end += length_to_add_one_side\n",
    "        if (prune_end):\n",
    "            start -= length_to_add_one_side\n",
    "            if (start - length_to_add_one_side >= 0):\n",
    "                start -= length_to_add_one_side\n",
    "        if (not prune_start and not prune_end):\n",
    "            start -= length_to_add_one_side\n",
    "            end += length_to_add_one_side\n",
    "            \n",
    "        locs = [list(x) for x in locs]\n",
    "        locs[0][0] = start\n",
    "        locs[length - 1][1] = end\n",
    "        \n",
    "        john_hsu[\"padded_merged_regex_location\"][i] = locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 46700/46700 [00:31<00:00, 1481.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(john_hsu))):\n",
    "    generate_padded_context_windows(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 46700/46700 [00:02<00:00, 16677.50it/s]\n"
     ]
    }
   ],
   "source": [
    "padded_seqs = []\n",
    "\n",
    "for i in tqdm(range(len(john_hsu))):\n",
    "    padded_seqs.append(pull_context_windows(i, \"padded_merged_regex_location\"))\n",
    "\n",
    "john_hsu[\"padded_regex_sent\"] = padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu['regex_matches'] = john_hsu['regex_matches'].astype(str)\n",
    "john_hsu['regex_matches'] = john_hsu['regex_matches'].str.replace(\"\\[\\]\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu['padded_regex_sent'] = john_hsu['padded_regex_sent'].astype(str)\n",
    "john_hsu['padded_regex_sent'] = john_hsu['padded_regex_sent'].str.replace('[', '')\n",
    "john_hsu['padded_regex_sent'] = john_hsu['padded_regex_sent'].str.replace(']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu.dropna(subset=[\"padded_regex_sent\"])\n",
    "john_hsu['padded_regex_sent'] = john_hsu['padded_regex_sent'].str.replace('\"', \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_preprocessing(note):\n",
    "    note = re.sub(r'   • ', ' ; ', note)\n",
    "    note = re.sub(r'[ ]{4,}', ' ', note)\n",
    "    note = re.sub(r'  ', '\\n', note)\n",
    "    note = re.sub(r'    ', '\\n\\n', note)\n",
    "    return note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 46700/46700 [00:03<00:00, 12788.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(john_hsu))):\n",
    "    john_hsu.at[i, \"padded_regex_sent_preprocessed\"] = note_preprocessing(john_hsu.at[i, \"padded_regex_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu[\"sequence_length\"] = john_hsu['padded_regex_sent_preprocessed'].astype(str).map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clinical_bert_tokenize(i):\n",
    "    tokens = tokenizer.encode_plus(john_hsu[\"padded_regex_sent_preprocessed\"][i], add_special_tokens = False, return_tensors = 'pt')\n",
    "\n",
    "    return (len(tokens['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 46700/46700 [01:18<00:00, 594.00it/s]\n"
     ]
    }
   ],
   "source": [
    "token_lens = []\n",
    "\n",
    "for i in tqdm(range(len(john_hsu))):\n",
    "    token_lens.append(clinical_bert_tokenize(i))\n",
    "\n",
    "john_hsu[\"padded_token_length\"] = token_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7734"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(john_hsu[john_hsu[\"padded_token_length\"] > 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu_no_padding = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Preprocessing\\Getting_Data\\Matches\\john_hsu_dataset_matches_no_padding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7647"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(john_hsu_no_padding[john_hsu_no_padding[\"token_length\"] > 510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = pd.read_csv(r\"Matches/john_hsu_dataset_matches_padding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu = john_hsu.drop_duplicates(subset = [\"padded_regex_sent_preprocessed\", \"NoteID\"], keep = \"last\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    46664.000000\n",
       "mean       382.321533\n",
       "std        322.555366\n",
       "min          0.000000\n",
       "25%        255.000000\n",
       "50%        306.000000\n",
       "75%        380.000000\n",
       "max       5160.000000\n",
       "Name: padded_token_length, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_hsu[\"padded_token_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu_no_padding = john_hsu_no_padding.drop_duplicates(subset = [\"regex_sent_preprocessed\", \"NoteID\"], keep = \"last\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    46692.000000\n",
       "mean       315.864024\n",
       "std        347.917413\n",
       "min          0.000000\n",
       "25%        136.000000\n",
       "50%        179.000000\n",
       "75%        367.000000\n",
       "max       5160.000000\n",
       "Name: token_length, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_hsu_no_padding[\"token_length\"].describe() # ax = john_hsu.plot.bar(y = \"token_length\", rot = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu[:1000].to_csv(r\"Matches/john_hsu_dataset_1000_padding.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_hsu.to_csv(r\"Matches/john_hsu_dataset_matches_padding.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_sequence_count = pd.DataFrame(columns = [\"PatientID\", \"sequence_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(john_hsu[\"PatientID\"].unique())):\n",
    "    count = len(john_hsu[john_hsu[\"PatientID\"] == john_hsu[\"PatientID\"].unique()[i]])\n",
    "    patient_sequence_count.loc[i] = (john_hsu[\"PatientID\"].unique()[i], count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_sequence_count.to_csv(r\"Matches/patient_level_sequence_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_sequence_count = pd.read_csv(r\"Matches/patient_level_sequence_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    952.000000\n",
       "mean      49.016807\n",
       "std       60.968176\n",
       "min        1.000000\n",
       "25%       10.000000\n",
       "50%       27.000000\n",
       "75%       65.250000\n",
       "max      457.000000\n",
       "Name: sequence_count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_sequence_count[\"sequence_count\"].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
