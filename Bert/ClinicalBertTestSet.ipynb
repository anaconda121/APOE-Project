{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import itertools\n",
    "import sklearn.metrics as sk\n",
    "from functools import reduce\n",
    "\n",
    "# deep learning libraries\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "# hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna.visualization.matplotlib as oviz\n",
    "\n",
    "# file system manipulation\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# set seeds to make computations deterministic\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# check CUDA availability\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"Is CUDA available? \", \"Yes\" if cuda_available else \"No\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Is CUDA available?  Yes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "final_test = pd.read_csv(r\"Storage/Bert/test_8_11.csv\")\n",
    "final_test.columns = [\"PatientID\", \"text\", \"labels\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "best_model = ClassificationModel(\n",
    "    \"bert\",\n",
    "    \"Storage/Bert/NoHyperParameterTuningResults/trial_0\"\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "test_results, test_outputs, test_wrong = best_model.eval_model(\n",
    "    final_test,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1bfef216abd4f729c4aa8e80575b8a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/74 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4447c5db9d9e47bf80ccf971c8601c56"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "max_prob_list = []\n",
    "test_prob_list = []\n",
    "test_pred_list = []\n",
    "for i in range(len(final_test)):\n",
    "    # prob_list = list(torch.softmax(torch.from_numpy(model_outputs[i]), axis=0)[:,1])\n",
    "    prob_list = torch.softmax(torch.from_numpy(test_outputs[i]), axis=0)\n",
    "    #print(\"Prob List: \", prob_list, type(prob_list))\n",
    "\n",
    "    extracted_prob_list = []\n",
    "    for i in range(len(prob_list)):\n",
    "        extracted_prob_list.append(float(prob_list[i]))\n",
    "\n",
    "    #print(\"Extracted Prob List: \", extracted_prob_list)\n",
    "    # find max one in each submatrix of length 3\n",
    "    max_proba = max(extracted_prob_list)\n",
    "\n",
    "    # identify model prediction based on location of max_proba within extracted_prob_list\n",
    "    if (extracted_prob_list[0] == max_proba):\n",
    "        test_pred_list.append(0)\n",
    "    elif (extracted_prob_list[1] == max_proba):\n",
    "        test_pred_list.append(1)\n",
    "    else:\n",
    "        test_pred_list.append(2)\n",
    "\n",
    "    max_prob_list.append(max_proba)\n",
    "    test_prob_list.append(extracted_prob_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "final_test[\"pred\"] = test_pred_list\n",
    "final_test[\"proba\"] = max_prob_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "revised_preds = pd.read_csv(r\"Storage/Bert/Revised Bert Preds.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "edits_made = 0\n",
    "for i in range(len(final_test)):\n",
    "    for j in range(len(revised_preds)):\n",
    "        if (final_test.at[i, \"text\"] == revised_preds.at[j, \"text\"]):\n",
    "            edits_made += 1\n",
    "            final_test.at[i, \"labels\"] = revised_preds.at[j, \"labels\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "sk.accuracy_score(test_pred_list, final_test[\"labels\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9283276450511946"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "final_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PatientID                                               text  labels  pred  \\\n",
       "0   Z9096104  ital status: married civil union spouse name: ...       1     1   \n",
       "1   Z7410349  history narrative social history tobacco quit ...       1     1   \n",
       "2   Z7754903  ncy-based suicidal statements. suicidal homici...       0     0   \n",
       "3  Z11959548  js; bjshingleton li61ao +21.5d target plano • ...       1     1   \n",
       "4   Z7580275  rts pedal edema is worsened recently. current ...       2     2   \n",
       "\n",
       "      proba  \n",
       "0  0.999421  \n",
       "1  0.999419  \n",
       "2  0.999304  \n",
       "3  0.999390  \n",
       "4  0.997088  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>pred</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z9096104</td>\n",
       "      <td>ital status: married civil union spouse name: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z7410349</td>\n",
       "      <td>history narrative social history tobacco quit ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z7754903</td>\n",
       "      <td>ncy-based suicidal statements. suicidal homici...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z11959548</td>\n",
       "      <td>js; bjshingleton li61ao +21.5d target plano • ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z7580275</td>\n",
       "      <td>rts pedal edema is worsened recently. current ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "sk.roc_auc_score(final_test[\"labels\"], test_prob_list, multi_class = \"ovr\", average = \"weighted\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9764382581332275"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import pickle\n",
    "\n",
    "f = open(\"Storage/Bert/test_set_prob.pkl\", \"wb\")\n",
    "pickle.dump(str(test_prob_list), f)\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "target_names = ['Negative', 'Neither', 'Positive']\n",
    "results = metrics.classification_report(final_test[\"labels\"], final_test[\"pred\"], target_names = target_names, output_dict=True)\n",
    "results = pd.DataFrame(results).transpose()\n",
    "conf_mat = metrics.confusion_matrix(final_test[\"labels\"], final_test[\"pred\"])\n",
    "print(\"Micro F1: \", metrics.f1_score(final_test[\"labels\"], final_test[\"pred\"], average = \"micro\"))\n",
    "print(\"Macro F1: \", metrics.f1_score(final_test[\"labels\"], final_test[\"pred\"], average = \"macro\"))\n",
    "print(\"Weighted F1: \", metrics.f1_score(final_test[\"labels\"], final_test[\"pred\"], average = \"weighted\"))\n",
    "print(\"Confusion Matrix: \\n\", conf_mat)\n",
    "print(\"Classification Report: \\n\", results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Micro F1:  0.9283276450511946\n",
      "Macro F1:  0.9174209846839186\n",
      "Weighted F1:  0.9277437001702764\n",
      "Confusion Matrix: \n",
      " [[102   1   1]\n",
      " [  7 125   2]\n",
      " [  6   4  45]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score     support\n",
      "Negative       0.886957  0.980769  0.931507  104.000000\n",
      "Neither        0.961538  0.932836  0.946970  134.000000\n",
      "Positive       0.937500  0.818182  0.873786   55.000000\n",
      "accuracy       0.928328  0.928328  0.928328    0.928328\n",
      "macro avg      0.928665  0.910596  0.917421  293.000000\n",
      "weighted avg   0.930553  0.928328  0.927744  293.000000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "FP = conf_mat.sum(axis = 0) - np.diag(conf_mat) \n",
    "FN = conf_mat.sum(axis = 1) - np.diag(conf_mat)\n",
    "TP = np.diag(conf_mat)\n",
    "TN = conf_mat.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "print(\"Sensitivity: \", TPR)\n",
    "print(\"Specificity: \", TNR)\n",
    "print(\"NPV: \", NPV)\n",
    "print(\"PPV: \", PPV)\n",
    "print(\"FPR: \", FPR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sensitivity:  [0.98076923 0.93283582 0.81818182]\n",
      "Specificity:  [0.93121693 0.96855346 0.98739496]\n",
      "NPV:  [0.98876404 0.94478528 0.95918367]\n",
      "PPV:  [0.88695652 0.96153846 0.9375    ]\n",
      "FPR:  [0.06878307 0.03144654 0.01260504]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "(0.93121693 +  0.96855346 + 0.98739496) / 3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9623884500000001"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "(0.98076923 + 0.93283582 + 0.81818182) / 3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9105956233333333"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('apoe-dl-env': venv)"
  },
  "interpreter": {
   "hash": "b0168968bb7ecfa78684047e3c95d55595c46869da584ba4da41f68e310286ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}