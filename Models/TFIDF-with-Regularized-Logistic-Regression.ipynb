{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \n",
    "#  Author: Tanish Tyagi\n",
    "#  \n",
    "\n",
    
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix, average_precision_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Always Pattern, Manual Review, and Sample DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "always_patterns = pd.read_csv(\"Storage/Data/always_patterns.csv\") \n",
    "always_patterns = always_patterns[['Unnamed: 0', 'patient_id', 'sequence','original', 'label']]\n",
    "always_patterns.columns = ['Unnamed: 0', 'patient_id', 'sequence','original', 'annotator_label']\n",
    "always_patterns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_review = pd.read_csv(\"Storage/Data/manual_review.csv\")\n",
    "manual_review = manual_review[['Unnamed: 0', 'patient_id', 'sequence','original', 'label']]\n",
    "manual_review.columns = ['Unnamed: 0', 'patient_id', 'sequence','original', 'annotator_label']\n",
    "manual_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\BigDataSets\\Sampling\\sample_8_12.csv\") \n",
    "        # pd.read_csv(\"Storage/Data/20K_sample.csv\")\n",
    "sample = sample[[\"PatientID\", \"regex_sent\"]]\n",
    "sample.columns = ['patient_id', 'sequence']\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Sample DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sequence(seq):\n",
    "    #getting rid of special characters\n",
    "    specials = '/' #etc\n",
    "    seq_no_special_chars = seq.translate(str.maketrans(specials, ' '*len(specials)))\n",
    "    \n",
    "    #having only 1 space between words\n",
    "    n = 1\n",
    "    seq_no_spaces = (' '*n).join(seq_no_special_chars.split())\n",
    "    \n",
    "    return seq_no_spaces.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(sample))):\n",
    "    sample.loc[i, \"sequence\"] = clean_sequence(sample.loc[i][\"sequence\"][3:len(sample.loc[i][\"sequence\"]) - 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Train, Validation, Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code only needs to be run once as train_test_split does a different split every time. After first run, use saved CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = always_patterns[[\"patient_id\", \"sequence\"]]\n",
    "y = always_patterns[\"annotator_label\"]\n",
    "\n",
    "y_label = y.to_numpy()\n",
    "X_train, X_test_valid, y_train, y_test_valid = train_test_split(X,y,random_state=0,test_size=0.10, stratify=y_label)\n",
    "\n",
    "y_test_valid_label = y_test_valid.to_numpy()\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test_valid, y_test_valid, random_state=0, test_size=(0.25), stratify=y_test_valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = manual_review[[\"patient_id\", \"sequence\"]]\n",
    "y_2 = manual_review[\"annotator_label\"]\n",
    "\n",
    "y_label_2 = y_2.to_numpy()\n",
    "X_train_2, X_test_valid_2, y_train_2, y_test_valid_2 = train_test_split(X_2,y_2,random_state=0,test_size=0.3, stratify=y_label_2)\n",
    "\n",
    "y_test_valid_label_2 = y_test_valid_2.to_numpy()\n",
    "X_valid_2, X_test_2, y_valid_2, y_test_2 = train_test_split(X_test_valid_2, y_test_valid_2, random_state=0, test_size=(0.15/0.3), stratify=y_test_valid_label_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_train_2)\n",
    "y_train = y_train.append(y_train_2)\n",
    "\n",
    "X_test = X_test.append(X_test_2)\n",
    "y_test = y_test.append(y_test_2)\n",
    "\n",
    "X_valid = X_valid.append(X_valid_2)\n",
    "y_valid = y_valid.append(y_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_valid), len(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Saved CSVs to load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\train_8_11.csv\")\n",
    "y_train = X_train[\"annotator_label\"]\n",
    "X_train = X_train[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\valid_8_11.csv\")\n",
    "y_valid = X_valid[\"annotator_label\"]\n",
    "X_valid = X_valid[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\test_8_11.csv\")\n",
    "y_test = X_test[\"annotator_label\"]\n",
    "X_test = X_test[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = sample['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_world = real_world_sample[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_valid), len(X_test)# , len(X_sample), len(X_real_world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initatilizing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\",analyzer='word', token_pattern=r'\\b[A-Za-z0-9]+\\b')\n",
    "tfidf_train= tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_valid = tfidf_vectorizer.transform(X_valid)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "tfidf_sample = tfidf_vectorizer.transform(X_sample)\n",
    "#tfidf_real_world = tfidf_vectorizer.transform(X_real_world)\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_train = pd.DataFrame(tfidf_train.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "tfidf_valid = pd.DataFrame(tfidf_valid.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "tfidf_test = pd.DataFrame(tfidf_test.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "tfidf_sample = pd.DataFrame(tfidf_sample.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "#tfidf_real_world = pd.DataFrame(tfidf_real_world.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\tfidf_train_8_12.csv\", index = False)\n",
    "tfidf_valid.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\tfidf_valid_8_12.csv\", index = False)\n",
    "tfidf_test.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\tfidf_test_8_12.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_real_world.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\tfidf_real_sample.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train.shape, tfidf_valid.shape, tfidf_test.shape, tfidf_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\y_train_8_12.csv\", index = False)\n",
    "y_valid.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\y_valid_8_12.csv\", index = False)\n",
    "y_test.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\y_test_8_12.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying features with high correaltion using Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_features_df = pd.concat([tfidf_train, y_train.reset_index(drop=True)], axis = 1)\n",
    "tfidf_test_features_df = pd.concat([tfidf_test, y_test.reset_index(drop = True)], axis = 1)\n",
    "tfidf_valid_features_df = pd.concat([tfidf_valid, y_valid.reset_index(drop = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features_by_cor(df):\n",
    "    m = len(df.columns)\n",
    "    output = df.iloc[:,m-1] \n",
    "    output_list = output.tolist()\n",
    "    corrcoef_array = []\n",
    "\n",
    "    for i in range(0,m-2):\n",
    "        input_list = df.iloc[:,i].tolist()\n",
    "        cols = [input_list, output_list]\n",
    "        corrcoef = abs(np.corrcoef(cols)) \n",
    "        corrcoef_array = np.append(corrcoef_array,corrcoef[0,1])\n",
    "\n",
    "    feature_names = list(df)\n",
    "    feature_names = feature_names[0:m-2]\n",
    "    \n",
    "    output_df = pd.DataFrame(feature_names, columns=['Features'])\n",
    "    output_df['CorrCoef'] = corrcoef_array\n",
    "    output_df = output_df.sort_values('CorrCoef')\n",
    "    output_df = output_df.reset_index()\n",
    "    output_df = output_df.drop(columns = \"index\")\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_output_df = filter_features_by_cor(tfidf_train_features_df)\n",
    "tfidf_output_df = tfidf_output_df.sort_values(by=['CorrCoef'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_output_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_output_df.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Performance\\feature_correlation_binary_labels_8_12.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_features_df.drop(columns = 'annotator_label')\n",
    "tfidf_test_features_df.drop(columns = 'annotator_label')\n",
    "tfidf_valid_features_df.drop(columns = 'annotator_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Word Features through emprically tuned value of Pearson's Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_corr(corr, tfidf_output_df):\n",
    "    # Setting Correlation threshold\n",
    "    top_tfidf_features_df = tfidf_output_df[tfidf_output_df['CorrCoef'] > corr]\n",
    "    filtered_tfidf_train = tfidf_train_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "    filtered_tfidf_test = tfidf_test_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "    filtered_tfidf_valid = tfidf_valid_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "    \n",
    "    return top_tfidf_features_df, filtered_tfidf_train, filtered_tfidf_test, filtered_tfidf_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisitic_regression(X_train, y_train, X_test, y_test, c, want_report, want_conf_mat, save_model, name):\n",
    "    # fitting model\n",
    "    lr = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = c, random_state = 0, class_weight = 'balanced')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # predictions\n",
    "    y_pred = lr.predict(X_test)\n",
    "    y_prob = lr.predict_proba(X_test)\n",
    "\n",
    "    # collecting results\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob, multi_class = 'ovr', average = 'weighted')\n",
    "    # print(\"ACC: \", acc, \"AUC: \", auc)\n",
    "    \n",
    "    if (save_model == True):\n",
    "        pickle.dump(lr, open(\"Storage/Model/\" + name, 'wb'))\n",
    "    \n",
    "    if (want_report == True):\n",
    "        target_names = ['Negative', 'Neither', 'Positive']\n",
    "        results_lgr = classification_report(y_test, y_pred, target_names = target_names, output_dict=True)\n",
    "        results_lgr = pd.DataFrame(results_lgr).transpose()\n",
    "        print(\"Micro F1: \", metrics.f1_score(y_test, y_pred, average = \"micro\"))\n",
    "        print(\"Macro F1: \", metrics.f1_score(y_test, y_pred, average = \"macro\"))\n",
    "        print(\"Weighted F1: \", metrics.f1_score(y_test, y_pred, average = \"weighted\"))\n",
    "        \n",
    "        if (want_conf_mat == True):\n",
    "            return lr, acc, auc, c, results_lgr, confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "        return lr, acc, auc, c, results_lgr\n",
    "    \n",
    "    if (want_conf_mat == True):\n",
    "        return lr, acc, auc, c, confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "    return lr, acc, auc, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "    # ensuring straftification across label\n",
    "    yes = cross_validation[cross_validation[\"annotator_label\"] == 1].reset_index(drop = True)\n",
    "    no = cross_validation[cross_validation[\"annotator_label\"] == 0].reset_index(drop = True)\n",
    "    #ntr = cross_validation[cross_validation[\"annotator_label\"] == 1].reset_index(drop = True)\n",
    "    #print(len(yes), len(no), len(ntr))\n",
    "    \n",
    "    yes_count = len(yes) // n_folds\n",
    "    no_count = len(no) // n_folds\n",
    "    #ntr_count = len(ntr) // n_folds\n",
    "    #print(yes_count, no_count, ntr_count)\n",
    "    split = list()\n",
    "    fold_size = len(cross_validation) // n_folds\n",
    "\n",
    "    # shuffling data to avoid having to generate random nums through while loop\n",
    "    yes = yes.sample(frac=1).reset_index(drop=True)\n",
    "    no = no.sample(frac=1).reset_index(drop=True)\n",
    "    #ntr = ntr.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # creating folds\n",
    "    for i in tqdm(range(n_folds)):\n",
    "        fold = pd.DataFrame(columns = cross_validation.columns)\n",
    "\n",
    "        fold = fold.append(yes[yes_count * i : (yes_count * i) + yes_count])\n",
    "        #print(len(fold), \"YES\", )\n",
    "        fold = fold.append(no[no_count * i : (no_count * i) + no_count])\n",
    "        #print(len(fold), \"NO\", )\n",
    "        #fold = fold.append(ntr[ntr_count * i : (ntr_count * i) + ntr_count])\n",
    "        #print(len(fold), \"NTR\", ((ntr_count * i) + ntr_count) - (ntr_count * i))\n",
    "        split.append(fold)\n",
    "        \n",
    "    return split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, n_folds):\n",
    "    splits = cross_validation_split(dataset, n_folds)\n",
    "    \n",
    "    counter = 0\n",
    "    tfidf_all_df = pd.DataFrame()\n",
    "    df_list  = []\n",
    "    \n",
    "    for fold in splits:\n",
    "        train = splits.copy()\n",
    "        del train[counter]\n",
    "        train = pd.concat(train)\n",
    "        \n",
    "        y_train = train[\"annotator_label\"].reset_index(drop = True)\n",
    "        y_train = y_train.astype(int)\n",
    "        \n",
    "        y_test = fold[\"annotator_label\"].reset_index(drop = True)\n",
    "        y_test = y_test.astype(int)\n",
    "\n",
    "        train = train.drop(columns = [\"annotator_label\"])\n",
    "        fold = fold.drop(columns = [\"annotator_label\"])\n",
    "        \n",
    "        test = list()\n",
    "        corr_list = list(np.arange(1,30) * 0.01)\n",
    "       \n",
    "        for corr in corr_list:\n",
    "            acc_list = []\n",
    "            auc_list = []\n",
    "            c_list = []\n",
    "             \n",
    "            # filtering by correlation coefficient\n",
    "            top_tfidf_features_df = tfidf_output_df[tfidf_output_df['CorrCoef'] > corr]\n",
    "            filtered_tfidf_train = train.filter(items=top_tfidf_features_df['Features'])\n",
    "            filtered_tfidf_fold = fold.filter(items=top_tfidf_features_df['Features'])\n",
    "            filtered_tfidf_test = tfidf_test_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "            \n",
    "            #print(filtered_tfidf_train.shape)\n",
    "            #print(filtered_tfidf_fold.shape)\n",
    "            \n",
    "            # tuning for optimal lambda value\n",
    "            for c in [0.01, 0.1, 1, 10, 100]:\n",
    "                #name = \"Fold-\" + str((counter + 1)) + \"-Corr-\" + str(corr) + \"-C-\" + str(c) + \".sav\"\n",
    "                lr, acc, auc, c = logisitic_regression(filtered_tfidf_train, y_train, filtered_tfidf_fold, y_test, c, False, False, False, \"\")\n",
    "                acc_list.append(acc)\n",
    "                auc_list.append(auc)\n",
    "                c_list.append(c)\n",
    "            \n",
    "            # gathering model stats\n",
    "            acc_df = pd.DataFrame(acc_list, columns=['acc'])\n",
    "            auc_df = pd.DataFrame(auc_list, columns=['auc'])\n",
    "            c_df = pd.DataFrame(c_list, columns=['c_value'])\n",
    "            \n",
    "            assert len(acc_df) == len(auc_df) == len(c_df)\n",
    "            \n",
    "            #acc_df[\"fold_number\"] = auc_df[\"fold_number\"] = c_df[\"fold_number\"] = [counter] * len(auc_df)\n",
    "            \n",
    "            iter_df = pd.concat([c_df, acc_df, auc_df], axis=1)\n",
    "            iter_df['corr_thres'] = [corr] * len(iter_df)\n",
    "            iter_df['fold_number'] = [(counter + 1)] * len(iter_df)\n",
    "            df_list.append(iter_df)\n",
    "            \n",
    "        print(\"Completed Fold #: \", counter + 1)\n",
    "        counter += 1\n",
    "        \n",
    "        print(\"Stats DF has\", len(df_list), \"records\")\n",
    "        \n",
    "        #df_list.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Optimizing-data\\sample_stat_df.csv\", index = False)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = pd.concat([tfidf_train_features_df, tfidf_valid_features_df])\n",
    "tfidf_all_df = evaluate_algorithm(cross_validation, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_all_df = pd.concat(tfidf_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_list = list(np.arange(1,30) * 0.01)\n",
    "average_results_df = []\n",
    "\n",
    "for corr in corr_list:\n",
    "    for c in [0.01, 0.1, 1, 10, 100]:\n",
    "        filtered = tfidf_all_df[(tfidf_all_df[\"corr_thres\"] == corr) & (tfidf_all_df[\"c_value\"] == c)]\n",
    "        avg_auc = filtered[\"auc\"].mean()\n",
    "        avg_acc = filtered[\"acc\"].mean()\n",
    "\n",
    "        filler = np.arange(5, 9)**2\n",
    "        df = pd.DataFrame(filler.reshape(1, 4), columns = [\"c_value\", \"acc\", \"auc\", \"corr_thres\"])\n",
    "        df.loc[df.index] = [c, avg_acc, avg_auc, corr]\n",
    "        #print(df)\n",
    "        \n",
    "        average_results_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_results_df = pd.concat(average_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_results_df[average_results_df['auc'] == max(average_results_df['auc'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specific parameter setting performance\n",
    "corr = 0.01\n",
    "c = 10\n",
    "\n",
    "y_train_cross_valid = cross_validation[\"annotator_label\"]\n",
    "y_test_cross_valid = tfidf_test_features_df[\"annotator_label\"]\n",
    "\n",
    "cross_validation.drop(columns = [\"annotator_label\"])\n",
    "tfidf_test_features_df.drop(columns = [\"annotator_label\"])\n",
    "\n",
    "# Setting Correlation threshold\n",
    "top_tfidf_features_df = tfidf_output_df[tfidf_output_df['CorrCoef'] > corr]\n",
    "filtered_tfidf_train = cross_validation.filter(items=top_tfidf_features_df['Features'])\n",
    "filtered_tfidf_test = tfidf_test_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "\n",
    "# Running model\n",
    "lr, acc_optimized, auc_optimized, c_list, report, conf_mat = logisitic_regression(filtered_tfidf_train, y_train_cross_valid, filtered_tfidf_test, y_test_cross_valid, c, True, True, False, \"\")\n",
    "\n",
    "print(\"\\nC: \", c, \"\\n\", report)\n",
    "print(\"\\nAUC: \", auc_optimized)\n",
    "print(\"ACC: \", acc_optimized)\n",
    "print(\"\\nConfusion Matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(neither_yes)\n",
    "#precision_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = conf_mat.sum(axis = 0) - np.diag(conf_mat) \n",
    "FN = conf_mat.sum(axis = 1) - np.diag(conf_mat)\n",
    "TP = np.diag(conf_mat)\n",
    "TN = conf_mat.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "print(\"Sensitivity: \", TPR)\n",
    "print(\"Specificity: \", TNR)\n",
    "print(\"NPV: \", NPV)\n",
    "print(\"PPV: \", PPV)\n",
    "print(\"FPR: \", FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "train = pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X_valid.reset_index(drop = True)\n",
    "y_valid = y_valid.reset_index(drop = True)\n",
    "valid = pd.concat([X_valid, y_valid], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "test = pd.concat([X_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\train_8_11.csv\", index = False)\n",
    "valid.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\valid_8_11.csv\", index = False)\n",
    "test.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\test_8_11.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lr, open(\"Storage/\" + \"model_8_30.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 3\n",
    "\n",
    "pred_prob = lr.predict_proba(filtered_tfidf_test)\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_class):    \n",
    "    fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test, pred_prob[:,i], pos_label = i)\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "    \n",
    "lw = 2\n",
    "\n",
    "# plotting    \n",
    "plt.plot(fpr[0], tpr[0], linestyle='--', color='orange', label='TF-IDF (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='TF-IDF (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='TF-IDF (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#plt.title('AUROC Curve for TF-IDF')\n",
    "\n",
    "#plt.savefig('AUROC Curve for TF-IDF', dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
