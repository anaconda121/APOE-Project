{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix, average_precision_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Always Pattern, Manual Review, and Sample DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "always_patterns = pd.read_csv(\"Storage/Data/always_patterns.csv\") \n",
    "always_patterns = always_patterns[['Unnamed: 0', 'patient_id', 'sequence','original', 'label']]\n",
    "always_patterns.columns = ['Unnamed: 0', 'patient_id', 'sequence','original', 'annotator_label']\n",
    "always_patterns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_review = pd.read_csv(\"Storage/Data/manual_review.csv\")\n",
    "manual_review = manual_review[['Unnamed: 0', 'patient_id', 'sequence','original', 'label']]\n",
    "manual_review.columns = ['Unnamed: 0', 'patient_id', 'sequence','original', 'annotator_label']\n",
    "manual_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\BigDataSets\\Sampling\\sample_8_12.csv\") \n",
    "        # pd.read_csv(\"Storage/Data/20K_sample.csv\")\n",
    "sample = sample[[\"PatientID\", \"regex_sent\"]]\n",
    "sample.columns = ['patient_id', 'sequence']\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_world_sample = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Analysis\\real_world_sample.csv\")\n",
    "# real_world_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Sample DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sequence(seq):\n",
    "    #getting rid of special characters\n",
    "    specials = '/' #etc\n",
    "    seq_no_special_chars = seq.translate(str.maketrans(specials, ' '*len(specials)))\n",
    "    \n",
    "    #having only 1 space between words\n",
    "    n = 1\n",
    "    seq_no_spaces = (' '*n).join(seq_no_special_chars.split())\n",
    "    \n",
    "    return seq_no_spaces.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(sample))):\n",
    "    sample.loc[i, \"sequence\"] = clean_sequence(sample.loc[i][\"sequence\"][3:len(sample.loc[i][\"sequence\"]) - 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Train, Validation, Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code only needs to be run once as train_test_split does a different split every time. After first run, use saved CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = always_patterns[[\"patient_id\", \"sequence\"]]\n",
    "y = always_patterns[\"annotator_label\"]\n",
    "\n",
    "y_label = y.to_numpy()\n",
    "X_train, X_test_valid, y_train, y_test_valid = train_test_split(X,y,random_state=0,test_size=0.10, stratify=y_label)\n",
    "\n",
    "y_test_valid_label = y_test_valid.to_numpy()\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test_valid, y_test_valid, random_state=0, test_size=(0.25), stratify=y_test_valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = manual_review[[\"patient_id\", \"sequence\"]]\n",
    "y_2 = manual_review[\"annotator_label\"]\n",
    "\n",
    "y_label_2 = y_2.to_numpy()\n",
    "X_train_2, X_test_valid_2, y_train_2, y_test_valid_2 = train_test_split(X_2,y_2,random_state=0,test_size=0.3, stratify=y_label_2)\n",
    "\n",
    "y_test_valid_label_2 = y_test_valid_2.to_numpy()\n",
    "X_valid_2, X_test_2, y_valid_2, y_test_2 = train_test_split(X_test_valid_2, y_test_valid_2, random_state=0, test_size=(0.15/0.3), stratify=y_test_valid_label_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_train_2)\n",
    "y_train = y_train.append(y_train_2)\n",
    "\n",
    "X_test = X_test.append(X_test_2)\n",
    "y_test = y_test.append(y_test_2)\n",
    "\n",
    "X_valid = X_valid.append(X_valid_2)\n",
    "y_valid = y_valid.append(y_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_valid), len(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Saved CSVs to load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\train_8_11.csv\")\n",
    "y_train = X_train[\"annotator_label\"]\n",
    "X_train = X_train[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\valid_8_11.csv\")\n",
    "y_valid = X_valid[\"annotator_label\"]\n",
    "X_valid = X_valid[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\test_8_11.csv\")\n",
    "y_test = X_test[\"annotator_label\"]\n",
    "X_test = X_test[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = sample['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_world = real_world_sample[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_valid), len(X_test)# , len(X_sample), len(X_real_world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\",analyzer='word', token_pattern=r'\\b[A-Za-z0-9]+\\b')\n",
    "tfidf_train= tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_valid = tfidf_vectorizer.transform(X_valid)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "tfidf_sample = tfidf_vectorizer.transform(X_sample)\n",
    "#tfidf_real_world = tfidf_vectorizer.transform(X_real_world)\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_train = pd.DataFrame(tfidf_train.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "tfidf_valid = pd.DataFrame(tfidf_valid.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "tfidf_test = pd.DataFrame(tfidf_test.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "tfidf_sample = pd.DataFrame(tfidf_sample.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "#tfidf_real_world = pd.DataFrame(tfidf_real_world.A, columns = tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\tfidf_train_8_12.csv\", index = False)\n",
    "tfidf_valid.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\tfidf_valid_8_12.csv\", index = False)\n",
    "tfidf_test.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\tfidf_test_8_12.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_real_world.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\tfidf_real_sample.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_sample.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\BigDataSets\\tfidf_sample_8_12.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train.shape, tfidf_valid.shape, tfidf_test.shape, tfidf_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\y_train_8_12.csv\", index = False)\n",
    "y_valid.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\y_valid_8_12.csv\", index = False)\n",
    "y_test.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\y_test_8_12.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying features with high correaltion using Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(y):\n",
    "    for i in range(len(y)):\n",
    "        if (y[i] == 2):\n",
    "            # convert yes from 2 to 1\n",
    "            y[i] = 1\n",
    "        elif (y[i] == 1 or y[i] == 0):\n",
    "            # convert no/ntr from 0/1 to 0\n",
    "            y[i] = 0\n",
    "    return y\n",
    "y_train = convert_to_binary(y_train)\n",
    "y_valid = convert_to_binary(y_valid)\n",
    "y_test = convert_to_binary(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_features_df = pd.concat([tfidf_train, y_train.reset_index(drop=True)], axis = 1)\n",
    "tfidf_test_features_df = pd.concat([tfidf_test, y_test.reset_index(drop = True)], axis = 1)\n",
    "tfidf_valid_features_df = pd.concat([tfidf_valid, y_valid.reset_index(drop = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features_by_cor(df):\n",
    "    m = len(df.columns)\n",
    "    output = df.iloc[:,m-1] \n",
    "    output_list = output.tolist()\n",
    "    corrcoef_array = []\n",
    "\n",
    "    for i in range(0,m-2):\n",
    "        input_list = df.iloc[:,i].tolist()\n",
    "        cols = [input_list, output_list]\n",
    "        corrcoef = abs(np.corrcoef(cols)) \n",
    "        corrcoef_array = np.append(corrcoef_array,corrcoef[0,1])\n",
    "\n",
    "    feature_names = list(df)\n",
    "    feature_names = feature_names[0:m-2]\n",
    "    \n",
    "    output_df = pd.DataFrame(feature_names, columns=['Features'])\n",
    "    output_df['CorrCoef'] = corrcoef_array\n",
    "    output_df = output_df.sort_values('CorrCoef')\n",
    "    output_df = output_df.reset_index()\n",
    "    output_df = output_df.drop(columns = \"index\")\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_output_df = filter_features_by_cor(tfidf_train_features_df)\n",
    "tfidf_output_df = tfidf_output_df.sort_values(by=['CorrCoef'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_output_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_output_df.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Performance\\feature_correlation_binary_labels_8_12.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_features_df.drop(columns = 'annotator_label')\n",
    "tfidf_test_features_df.drop(columns = 'annotator_label')\n",
    "tfidf_valid_features_df.drop(columns = 'annotator_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_corr(corr, tfidf_output_df):\n",
    "    # Setting Correlation threshold\n",
    "    top_tfidf_features_df = tfidf_output_df[tfidf_output_df['CorrCoef'] > corr]\n",
    "    filtered_tfidf_train = tfidf_train_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "    filtered_tfidf_test = tfidf_test_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "    filtered_tfidf_valid = tfidf_valid_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "    \n",
    "    return top_tfidf_features_df, filtered_tfidf_train, filtered_tfidf_test, filtered_tfidf_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisitic_regression(X_train, y_train, X_test, y_test, c, want_report, want_conf_mat, save_model, name):\n",
    "    # fitting model\n",
    "    lr = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = c, random_state = 0, class_weight = 'balanced')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # predictions\n",
    "    y_pred = lr.predict(X_test)\n",
    "    y_prob = lr.predict_proba(X_test)\n",
    "\n",
    "    # collecting results\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob, multi_class = 'ovr', average = 'weighted')\n",
    "    # print(\"ACC: \", acc, \"AUC: \", auc)\n",
    "    \n",
    "    if (save_model == True):\n",
    "        pickle.dump(lr, open(\"Storage/Model/\" + name, 'wb'))\n",
    "    \n",
    "    if (want_report == True):\n",
    "        target_names = ['Negative', 'Neither', 'Positive']\n",
    "        results_lgr = classification_report(y_test, y_pred, target_names = target_names, output_dict=True)\n",
    "        results_lgr = pd.DataFrame(results_lgr).transpose()\n",
    "        print(\"Micro F1: \", metrics.f1_score(y_test, y_pred, average = \"micro\"))\n",
    "        print(\"Macro F1: \", metrics.f1_score(y_test, y_pred, average = \"macro\"))\n",
    "        print(\"Weighted F1: \", metrics.f1_score(y_test, y_pred, average = \"weighted\"))\n",
    "        \n",
    "        if (want_conf_mat == True):\n",
    "            return lr, acc, auc, c, results_lgr, confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "        return lr, acc, auc, c, results_lgr\n",
    "    \n",
    "    if (want_conf_mat == True):\n",
    "        return lr, acc, auc, c, confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "    return lr, acc, auc, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "    # ensuring straftification across label\n",
    "    yes = cross_validation[cross_validation[\"annotator_label\"] == 1].reset_index(drop = True)\n",
    "    no = cross_validation[cross_validation[\"annotator_label\"] == 0].reset_index(drop = True)\n",
    "    #ntr = cross_validation[cross_validation[\"annotator_label\"] == 1].reset_index(drop = True)\n",
    "    #print(len(yes), len(no), len(ntr))\n",
    "    \n",
    "    yes_count = len(yes) // n_folds\n",
    "    no_count = len(no) // n_folds\n",
    "    #ntr_count = len(ntr) // n_folds\n",
    "    #print(yes_count, no_count, ntr_count)\n",
    "    split = list()\n",
    "    fold_size = len(cross_validation) // n_folds\n",
    "\n",
    "    # shuffling data to avoid having to generate random nums through while loop\n",
    "    yes = yes.sample(frac=1).reset_index(drop=True)\n",
    "    no = no.sample(frac=1).reset_index(drop=True)\n",
    "    #ntr = ntr.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # creating folds\n",
    "    for i in tqdm(range(n_folds)):\n",
    "        fold = pd.DataFrame(columns = cross_validation.columns)\n",
    "\n",
    "        fold = fold.append(yes[yes_count * i : (yes_count * i) + yes_count])\n",
    "        #print(len(fold), \"YES\", )\n",
    "        fold = fold.append(no[no_count * i : (no_count * i) + no_count])\n",
    "        #print(len(fold), \"NO\", )\n",
    "        #fold = fold.append(ntr[ntr_count * i : (ntr_count * i) + ntr_count])\n",
    "        #print(len(fold), \"NTR\", ((ntr_count * i) + ntr_count) - (ntr_count * i))\n",
    "        split.append(fold)\n",
    "        \n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, n_folds):\n",
    "    splits = cross_validation_split(dataset, n_folds)\n",
    "    \n",
    "    counter = 0\n",
    "    tfidf_all_df = pd.DataFrame()\n",
    "    df_list  = []\n",
    "    \n",
    "    for fold in splits:\n",
    "        train = splits.copy()\n",
    "        del train[counter]\n",
    "        train = pd.concat(train)\n",
    "        \n",
    "        y_train = train[\"annotator_label\"].reset_index(drop = True)\n",
    "        y_train = y_train.astype(int)\n",
    "        \n",
    "        y_test = fold[\"annotator_label\"].reset_index(drop = True)\n",
    "        y_test = y_test.astype(int)\n",
    "\n",
    "        train = train.drop(columns = [\"annotator_label\"])\n",
    "        fold = fold.drop(columns = [\"annotator_label\"])\n",
    "        \n",
    "        test = list()\n",
    "        corr_list = list(np.arange(1,30) * 0.01)\n",
    "       \n",
    "        for corr in corr_list:\n",
    "            acc_list = []\n",
    "            auc_list = []\n",
    "            c_list = []\n",
    "             \n",
    "            # filtering by correlation coefficient\n",
    "            top_tfidf_features_df = tfidf_output_df[tfidf_output_df['CorrCoef'] > corr]\n",
    "            filtered_tfidf_train = train.filter(items=top_tfidf_features_df['Features'])\n",
    "            filtered_tfidf_fold = fold.filter(items=top_tfidf_features_df['Features'])\n",
    "            filtered_tfidf_test = tfidf_test_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "            \n",
    "            #print(filtered_tfidf_train.shape)\n",
    "            #print(filtered_tfidf_fold.shape)\n",
    "            \n",
    "            # tuning for optimal lambda value\n",
    "            for c in [0.01, 0.1, 1, 10, 100]:\n",
    "                #name = \"Fold-\" + str((counter + 1)) + \"-Corr-\" + str(corr) + \"-C-\" + str(c) + \".sav\"\n",
    "                lr, acc, auc, c = logisitic_regression(filtered_tfidf_train, y_train, filtered_tfidf_fold, y_test, c, False, False, False, \"\")\n",
    "                acc_list.append(acc)\n",
    "                auc_list.append(auc)\n",
    "                c_list.append(c)\n",
    "            \n",
    "            # gathering model stats\n",
    "            acc_df = pd.DataFrame(acc_list, columns=['acc'])\n",
    "            auc_df = pd.DataFrame(auc_list, columns=['auc'])\n",
    "            c_df = pd.DataFrame(c_list, columns=['c_value'])\n",
    "            \n",
    "            assert len(acc_df) == len(auc_df) == len(c_df)\n",
    "            \n",
    "            #acc_df[\"fold_number\"] = auc_df[\"fold_number\"] = c_df[\"fold_number\"] = [counter] * len(auc_df)\n",
    "            \n",
    "            iter_df = pd.concat([c_df, acc_df, auc_df], axis=1)\n",
    "            iter_df['corr_thres'] = [corr] * len(iter_df)\n",
    "            iter_df['fold_number'] = [(counter + 1)] * len(iter_df)\n",
    "            df_list.append(iter_df)\n",
    "            \n",
    "        print(\"Completed Fold #: \", counter + 1)\n",
    "        counter += 1\n",
    "        \n",
    "        print(\"Stats DF has\", len(df_list), \"records\")\n",
    "        \n",
    "        #df_list.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Optimizing-data\\sample_stat_df.csv\", index = False)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = pd.concat([tfidf_train_features_df, tfidf_valid_features_df])\n",
    "tfidf_all_df = evaluate_algorithm(cross_validation, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_all_df = pd.concat(tfidf_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_list = list(np.arange(1,30) * 0.01)\n",
    "average_results_df = []\n",
    "\n",
    "for corr in corr_list:\n",
    "    for c in [0.01, 0.1, 1, 10, 100]:\n",
    "        filtered = tfidf_all_df[(tfidf_all_df[\"corr_thres\"] == corr) & (tfidf_all_df[\"c_value\"] == c)]\n",
    "        avg_auc = filtered[\"auc\"].mean()\n",
    "        avg_acc = filtered[\"acc\"].mean()\n",
    "\n",
    "        filler = np.arange(5, 9)**2\n",
    "        df = pd.DataFrame(filler.reshape(1, 4), columns = [\"c_value\", \"acc\", \"auc\", \"corr_thres\"])\n",
    "        df.loc[df.index] = [c, avg_acc, avg_auc, corr]\n",
    "        #print(df)\n",
    "        \n",
    "        average_results_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_results_df = pd.concat(average_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_results_df[average_results_df['auc'] == max(average_results_df['auc'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific parameter setting performance\n",
    "corr = 0.01\n",
    "c = 10\n",
    "\n",
    "y_train_cross_valid = cross_validation[\"annotator_label\"]\n",
    "y_test_cross_valid = tfidf_test_features_df[\"annotator_label\"]\n",
    "\n",
    "cross_validation.drop(columns = [\"annotator_label\"])\n",
    "tfidf_test_features_df.drop(columns = [\"annotator_label\"])\n",
    "\n",
    "# Setting Correlation threshold\n",
    "top_tfidf_features_df = tfidf_output_df[tfidf_output_df['CorrCoef'] > corr]\n",
    "filtered_tfidf_train = cross_validation.filter(items=top_tfidf_features_df['Features'])\n",
    "filtered_tfidf_test = tfidf_test_features_df.filter(items=top_tfidf_features_df['Features'])\n",
    "\n",
    "# Running model\n",
    "lr, acc_optimized, auc_optimized, c_list, report, conf_mat = logisitic_regression(filtered_tfidf_train, y_train_cross_valid, filtered_tfidf_test, y_test_cross_valid, c, True, True, False, \"\")\n",
    "\n",
    "print(\"\\nC: \", c, \"\\n\", report)\n",
    "print(\"\\nAUC: \", auc_optimized)\n",
    "print(\"ACC: \", acc_optimized)\n",
    "print(\"\\nConfusion Matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tfidf_test[\"label\"] = y_test_cross_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_neither = filtered_tfidf_test[filtered_tfidf_test[\"label\"] == 1]\n",
    "y_test_no = filtered_tfidf_test[filtered_tfidf_test[\"label\"] == 0]\n",
    "y_test_yes = filtered_tfidf_test[filtered_tfidf_test[\"label\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tfidf_test = filtered_tfidf_test.drop(columns = [\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neither_yes = pd.concat([y_test_neither, y_test_yes], axis = 0)\n",
    "neither_yes = neither_yes.drop(columns = [\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neither_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(neither_yes)\n",
    "#precision_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "      NO   NTR YES\n",
    "NO  [[439  9  21]\n",
    "NTR [  5 457   7]\n",
    "YES [ 26  19 424]]\n",
    "\n",
    "NO - 439/469 TP, 9/469 NTR when should be NO, and 21/469 YES when should be NO\n",
    "    Precision: 439/(439+5+26)\n",
    "    Recall: 439/(439+21+9)\n",
    "    fl: (439*2)/(470+469)\n",
    "\n",
    "NTR - 457/469 TP, 5/469 NO when should be NTR, and 7/469 YES when should be NTR\n",
    "YES - 424/469 TP, 19/469 NTR when should be YES, and 26/469 are NO when should be YES\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "      NO   NTR YES\n",
    "NO  [[83  7  14]\n",
    "NTR  [10 124  7]\n",
    "YES  [6  3   39]]\n",
    "\n",
    "no\n",
    "tpr: 0.8\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = conf_mat.sum(axis = 0) - np.diag(conf_mat) \n",
    "FN = conf_mat.sum(axis = 1) - np.diag(conf_mat)\n",
    "TP = np.diag(conf_mat)\n",
    "TN = conf_mat.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "print(\"Sensitivity: \", TPR)\n",
    "print(\"Specificity: \", TNR)\n",
    "print(\"NPV: \", NPV)\n",
    "print(\"PPV: \", PPV)\n",
    "print(\"FPR: \", FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "train = pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X_valid.reset_index(drop = True)\n",
    "y_valid = y_valid.reset_index(drop = True)\n",
    "valid = pd.concat([X_valid, y_valid], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "test = pd.concat([X_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\train_8_11.csv\", index = False)\n",
    "valid.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\valid_8_11.csv\", index = False)\n",
    "test.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Data\\test_8_11.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lr, open(\"Storage/\" + \"model_8_30.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_output_df = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Performance\\feature_correlation_multiclass_labels_8_12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tfidf_features_df_sample = tfidf_output_df[tfidf_output_df['CorrCoef'] > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\model_8_30.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Train and Test Set Predictions and  Probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(r\"C:\\Users\\tanis\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\data\\train_8_11.csv\")\n",
    "#valid = pd.read_csv(r\"C:\\Users\\tanis\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\data\\valid_8_11.csv\")\n",
    "#cross_validation_df = pd.concat([train, valid])\n",
    "\n",
    "test = pd.read_csv(r\"C:\\Users\\tanis\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\data\\test_8_11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(tfidf_test.filter(items = top_tfidf_features_df_sample['Features']))\n",
    "#cross_valid_predictions = model.predict(cross_validation.filter(items = top_tfidf_features_df_sample['Features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_validation_df[\"predictions\"] = cross_valid_predictions\n",
    "test[\"predictions\"] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = model.predict_proba(tfidf_test.filter(items = top_tfidf_features_df_sample['Features']))\n",
    "#cross_valid_proba = model.predict_proba(cross_validation.filter(items = top_tfidf_features_df_sample['Features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = test_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"probability\"] = test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_proba = np.array([[x] for x in np.max(test_proba, axis=1)])\n",
    "# test_proba = [item for sublist in test_proba for item in sublist]\n",
    "# test[\"probability\"] = test_proba\n",
    "\n",
    "# cross_valid_proba = np.array([[x] for x in np.max(cross_valid_proba, axis=1)])\n",
    "# cross_valid_proba = [item for sublist in cross_valid_proba for item in sublist]\n",
    "# cross_validation_df[\"probability\"] = cross_valid_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(y):\n",
    "    for i in range(len(y)):\n",
    "        if (y[i] == 2):\n",
    "            # convert yes from 2 to 1\n",
    "            y[i] = 1\n",
    "        elif (y[i] == 1 or y[i] == 0):\n",
    "            # convert no/ntr from 0/1 to 0\n",
    "            y[i] = 0\n",
    "    return y\n",
    "\n",
    "test[\"annotator_label\"] = convert_to_binary(test[\"annotator_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_validation_df.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Baseline_Model\\data\\train_full.csv\", index = False)\n",
    "test.to_csv(r\"C:\\Users\\tanis\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Baseline_Model\\data\\test_binary_classification.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cross_validation_df[\"patient_id\"].unique()), len(cross_validation_df), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predictions = model.predict(tfidf_sample.filter(items = top_tfidf_features_df_sample['Features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"predictions\"] = sample_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_proba = model.predict_proba(tfidf_sample.filter(items = top_tfidf_features_df_sample['Features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_proba = np.array([[x] for x in np.max(sample_proba, axis=1)])\n",
    "sample_proba = [item for sublist in sample_proba for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"probability\"] = sample_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\Predictions\\sample_predictions_9_1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Optimal Patient Aggregation Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apoe = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Baseline_Model\\data\\tanish_predictions_with_structured_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apoe_e2 = apoe[(apoe[\"APOE\"] == \"e2/e2\") | (apoe[\"APOE\"] == \"e2/e3\")]\n",
    "len((apoe_e2[apoe_e2[\"patient_CI\"] == 1]))/len(apoe_e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = pickle.load(open(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\Storage\\model_8_12_binary_classification.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tfidf_features_df_sample_binary = tfidf_output_df[tfidf_output_df['CorrCoef'] > 0.07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_sample_predictions = binary_model.predict(tfidf_sample.filter(items = top_tfidf_features_df_sample_binary['Features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_sample_preds = sample.copy()\n",
    "binary_sample_preds[\"predictions\"] = binary_sample_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_sample_preds[\"predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_sample_preds = pd.merge(binary_sample_preds, apoe, how = \"right\", on = \"patient_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_preds_cp = sample.copy()\n",
    "sample_preds_cp = pd.merge(sample_preds_cp, apoe, how = \"right\", on = \"patient_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_sample_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apoe[\"APOE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_2 = sample_preds_cp[(sample_preds_cp[\"APOE\"] == \"e2/e2\") | (sample_preds_cp[\"APOE\"] == \"e2/e3\")]\n",
    "e_3 = sample_preds_cp[(sample_preds_cp[\"APOE\"] == \"e3/e3\")]\n",
    "e_4 = sample_preds_cp[(sample_preds_cp[\"APOE\"] == \"e4/e4\") | (sample_preds_cp[\"APOE\"] == \"e2/e4 or e1/e3\") | (sample_preds_cp[\"APOE\"] == \"e3/e4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(e_2), len(e_3), len(e_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_ci(df, sequence_threshold):\n",
    "    patient_level_preds = []\n",
    "    p_id_ls = []\n",
    "    ci_count = 0\n",
    "    for p_id in df[\"patient_id\"].unique():\n",
    "        sequences = df[df[\"patient_id\"] == p_id]\n",
    "        if len(sequences[sequences[\"predictions\"] == 2]) >= sequence_threshold:\n",
    "            patient_level_preds.append(1)\n",
    "            ci_count += 1\n",
    "        else:\n",
    "            patient_level_preds.append(0)\n",
    "        p_id_ls.append(p_id)\n",
    "    return patient_level_preds, ci_count/len(df[\"patient_id\"].unique()), p_id_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = []\n",
    "y_axis_e2 = []\n",
    "y_axis_e3 = []\n",
    "y_axis_e4 = []\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    e_2_preds, e_2_percent, e_2_p_id = percent_ci(e_2, i+1)\n",
    "    e_3_preds, e_3_percent, e_3_p_id = percent_ci(e_3, i+1)\n",
    "    e_4_preds, e_4_percent, e_4_p_id = percent_ci(e_4, i+1)\n",
    "    \n",
    "    x_axis.append(i+1)\n",
    "    y_axis_e2.append(e_2_percent)\n",
    "    y_axis_e3.append(e_3_percent)\n",
    "    y_axis_e4.append(e_4_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_axis, y_axis_e2, label='APOE ε2')\n",
    "plt.plot(x_axis, y_axis_e3, label='APOE ε3')\n",
    "plt.plot(x_axis, y_axis_e4, label='APOE ε4')\n",
    "\n",
    "plt.xlabel(\"Sequence Threshold\")\n",
    "plt.ylabel(\"Percent of Patients Predicted as having CI\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_preds = pd.DataFrame()\n",
    "revised_preds[\"patient_id\"] = e_2_p_id + (e_3_p_id) + (e_4_p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_preds[\"predictions\"] = e_2_preds + (e_3_preds) + (e_4_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_preds[\"predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_patients = pd.merge(apoe, revised_preds, how = \"right\", on = \"patient_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_patients.drop(columns = [\"patient_CI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = len(revised_patients[(revised_patients[\"predictions\"] == 1) & (revised_patients[\"AD_Med_or_ICD_Code\"] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(note.loc[note['id'] == 8481]['PatientID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = len(revised_patients[(revised_patients[\"predictions\"] == 1) & (revised_patients[\"AD_Med_or_ICD_Code\"] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = len(revised_patients[(revised_patients[\"predictions\"] == 0) & (revised_patients[\"AD_Med_or_ICD_Code\"] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN = len(revised_patients[(revised_patients[\"predictions\"] == 0) & (revised_patients[\"AD_Med_or_ICD_Code\"] == 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 3\n",
    "\n",
    "pred_prob = lr.predict_proba(filtered_tfidf_test)\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_class):    \n",
    "    fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test, pred_prob[:,i], pos_label = i)\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "    \n",
    "lw = 2\n",
    "\n",
    "# plotting    \n",
    "plt.plot(fpr[0], tpr[0], linestyle='--', color='orange', label='TF-IDF (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='TF-IDF (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='TF-IDF (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#plt.title('AUROC Curve for TF-IDF')\n",
    "\n",
    "#plt.savefig('AUROC Curve for TF-IDF', dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
