{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import itertools\n",
    "import sklearn.metrics as sk\n",
    "from functools import reduce\n",
    "\n",
    "# deep learning libraries\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "# hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna.visualization.matplotlib as oviz\n",
    "\n",
    "# file system manipulation\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "import time# base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import itertools\n",
    "import sklearn.metrics as sk\n",
    "from functools import reduce\n",
    "\n",
    "# deep learning libraries\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "# hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna.visualization.matplotlib as oviz\n",
    "\n",
    "# file system manipulation\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "import time"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Matplotlib created a temporary config/cache directory at /scratch/matplotlib-7p99_1fw because the default path (/users/tt377/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# define directories\n",
    "data_dir = Path(\"Storage/Bert/\")\n",
    "results_dir = Path(\"Storage/Bert/Results\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# set seeds to make computations deterministic\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# check CUDA availability\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"Is CUDA available? \", \"Yes\" if cuda_available else \"No\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Is CUDA available?  Yes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# configure logging options\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def prepare_data(trial):\n",
    "    train_data = pd.read_csv(r\"Storage/Bert/train_8_11.csv\")\n",
    "    val_data = pd.read_csv(r\"Storage/Bert/valid_8_11.csv\")\n",
    "    test_data = pd.read_csv(r\"Storage/Bert/test_8_11.csv\")\n",
    "        \n",
    "    # always_patterns = pd.read_csv(\"Storage/Bert/always_patterns.csv\") \n",
    "    # always_patterns = always_patterns[['Unnamed: 0', 'patient_id', 'sequence','original', 'label']]\n",
    "    # always_patterns.columns = ['Unnamed: 0', 'patient_id', 'sequence','original', 'annotator_label']\n",
    "    \n",
    "    # manual_review = pd.read_csv(\"Storage/Bert/manual_review.csv\")\n",
    "    # manual_review = manual_review[['Unnamed: 0', 'patient_id', 'sequence','original', 'label']]\n",
    "    # manual_review.columns = ['Unnamed: 0', 'patient_id', 'sequence','original', 'annotator_label']\n",
    "    \n",
    "    # # stratification among always patterns\n",
    "    # X = always_patterns[[\"patient_id\", \"sequence\"]]\n",
    "    # y = always_patterns[\"annotator_label\"]\n",
    "\n",
    "    # y_label = y.to_numpy()\n",
    "    # X_train, X_test_valid, y_train, y_test_valid = train_test_split(X, y, random_state=None, test_size=0.10, stratify=y_label)\n",
    "\n",
    "    # y_test_valid_label = y_test_valid.to_numpy()\n",
    "    # X_valid, X_test, y_valid, y_test = train_test_split(X_test_valid, y_test_valid, random_state=None, test_size=(0.25), stratify=y_test_valid_label)\n",
    "    \n",
    "    # # stratification among manually reviewed sequences\n",
    "    # X_2 = manual_review[[\"patient_id\", \"sequence\"]]\n",
    "    # y_2 = manual_review[\"annotator_label\"]\n",
    "\n",
    "    # y_label_2 = y_2.to_numpy()\n",
    "    # X_train_2, X_test_valid_2, y_train_2, y_test_valid_2 = train_test_split(X_2,y_2,random_state=None,test_size=0.3, stratify=y_label_2)\n",
    "\n",
    "    # y_test_valid_label_2 = y_test_valid_2.to_numpy()\n",
    "    # X_valid_2, X_test_2, y_valid_2, y_test_2 = train_test_split(X_test_valid_2, y_test_valid_2, random_state=None, test_size=(0.15/0.3), stratify=y_test_valid_label_2)\n",
    "    \n",
    "    # # combining\n",
    "    # X_train = X_train.append(X_train_2)\n",
    "    # y_train = y_train.append(y_train_2)\n",
    "\n",
    "    # X_test = X_test.append(X_test_2)\n",
    "    # y_test = y_test.append(y_test_2)\n",
    "\n",
    "    # X_valid = X_valid.append(X_valid_2)\n",
    "    # y_valid = y_valid.append(y_valid_2)\n",
    "    \n",
    "    # # data = X + y\n",
    "    # train_data = pd.concat([X_train.reset_index(drop = True), y_train.reset_index(drop = True)], axis = 1)\n",
    "    # val_data = pd.concat([X_valid.reset_index(drop = True), y_valid.reset_index(drop = True)], axis = 1)\n",
    "    # test_data = pd.concat([X_test.reset_index(drop = True), y_test.reset_index(drop = True)], axis = 1)\n",
    "    \n",
    "    train_data.columns = val_data.columns = test_data.columns = [\"PatientID\", \"text\", \"labels\"]\n",
    "\n",
    "    return train_data, val_data, test_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def define_model(trial, trial_dir):\n",
    "    # hyperparameter tuning\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-8, 1e-4, log = True)\n",
    "    adam_epsilon = trial.suggest_float(\"adam_epilson\", 1e-8, 1e-4, log = True)\n",
    "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 1, 3)\n",
    "    early_stopping_patience = trial.suggest_int(\"early_stopping_patience\", 1, 3)\n",
    "\n",
    "    print(\"- Learning Rate: {}\".format(learning_rate))\n",
    "    print(\"- Adam Epsilon: {}\".format(adam_epsilon)) \n",
    "    print(\"- Training Epochs: {}\".format(num_train_epochs))\n",
    "    print(\"- Early Stopping Patience: {}\".format(early_stopping_patience))\n",
    "\n",
    "    # define model name\n",
    "    model_type = \"bert\"\n",
    "    model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "    max_seq_length = 512 \n",
    "\n",
    "    model_args = ClassificationArgs(\n",
    "\n",
    "    ## NLP ARGUMENTS\n",
    "    sliding_window = False,\n",
    "    learning_rate = learning_rate, # default 4e-5\n",
    "    adam_epsilon = adam_epsilon, # default 1e-8\n",
    "    train_batch_size = 8, # default 8\n",
    "    eval_batch_size = 4, # default 8\n",
    "    num_train_epochs = num_train_epochs,  # default 1 (number of epochs model will be trained for)\n",
    "    do_lower_case = False, # default False\n",
    "    max_seq_length = max_seq_length, # default 128 (maximum sequence length the model will support)\n",
    "    \n",
    "    ## TRAINING LOOP\n",
    "    logging_steps = 50, # default 50\n",
    "    manual_seed = 1234, # default None (necessary for reproducible results)\n",
    "    n_gpu = 2, # default 1 (number of GPUs to use)\n",
    "    save_steps = 2000, # default 2000 (save a model checkpoint at every specified number of steps)\n",
    "    output_dir = trial_dir, \n",
    "    overwrite_output_dir = True, # default False (if True, then the trained model will be saved to the ouput_dir and will overwrite existing saved models in the same directory)\n",
    "    \n",
    "    ## EVALUATE DURING TRAINING\n",
    "    evaluate_during_training = True, # default False\n",
    "    evaluate_during_training_steps = 2000, # default  2000  \n",
    "    evaluate_during_training_verbose = True, # default False\n",
    "    \n",
    "    ## EARLY STOPPING\n",
    "    use_early_stopping = True, # default False\n",
    "    early_stopping_delta = 0, # default 0 (improvement over best_eval_loss necessary to count as a better checkpoint)\n",
    "    early_stopping_metric = \"eval_loss\", # default eval_loss \n",
    "    early_stopping_metric_minimize = True, # default True\n",
    "    early_stopping_patience = early_stopping_patience, # default value 3 (terminate training after these many epochs if there is no improvement in early_stopping_metric then early_stopping_delta)\n",
    "    \n",
    "    )\n",
    "    \n",
    "    # create the classification model\n",
    "    model = ClassificationModel(\n",
    "        model_type, model_name,\n",
    "        num_labels = 3,\n",
    "        args = model_args,\n",
    "        use_cuda = cuda_available\n",
    "    )\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def objective(trial):\n",
    "    # log time\n",
    "    start_time = time.localtime()\n",
    "\n",
    "    # log message\n",
    "    print(\"\\n-------- TRIAL #{} --------\".format(trial.number))\n",
    "\n",
    "    # create output directory\n",
    "    trial_dir = \"Storage/Bert/Results/trial_{}\".format(trial.number)\n",
    "    if os.path.isdir(trial_dir):\n",
    "        shutil.rmtree(trial_dir)\n",
    "        print(\"\\n>>> {}: Removing Directory {}\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime()), trial_dir))\n",
    "    os.mkdir(trial_dir)\n",
    "\n",
    "    # log message\n",
    "    print(\"\\n>>> {}: Preparing Data\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime())))\n",
    "\n",
    "    train_data, val_data, test_data = prepare_data(trial)\n",
    "\n",
    "    assert len(train_data[\"labels\"].unique() == 3)\n",
    "    \n",
    "    # save test dataset to file\n",
    "    f = open(Path(trial_dir, \"data_{}.pkl\".format(trial.number)), \"wb\")\n",
    "    pickle.dump([train_data, val_data, test_data], f)\n",
    "    f.close()\n",
    "\n",
    "    # log message\n",
    "    print(\"\\n>>> {}: Defining Model\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime())))\n",
    "\n",
    "    model = define_model(trial, trial_dir)\n",
    "\n",
    "    # log message\n",
    "    print(\"\\n>>> {}: Started Training\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime())))\n",
    "\n",
    "    # train model\n",
    "    model.train_model(\n",
    "        train_data,\n",
    "        eval_df = val_data,\n",
    "        # auc = sk.roc_auc_score,\n",
    "        # acc = sk.accuracy_score\n",
    "    )\n",
    "\n",
    "    print(\"\\n>>> {}: Started Evaluation on Validation Set\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime())))\n",
    "    \n",
    "    results, model_outputs, wrong_predictions = model.eval_model(\n",
    "        val_data,\n",
    "        # auc = sk.roc_auc_score,\n",
    "        # acc = sk.accuracy_score\n",
    "    )\n",
    "\n",
    "    # save to file\n",
    "    f = open(Path(trial_dir, \"training_results_{}.pkl\".format(trial.number)), \"wb\")\n",
    "    pickle.dump([model, results, model_outputs, wrong_predictions], f)\n",
    "    f.close()\n",
    "\n",
    "    # output message, initialize empty list\n",
    "    print(\">>> {}: Get Sequence Probabilities\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime())))\n",
    "    df_list = []\n",
    "\n",
    "    # extract context window probabilities\n",
    "    max_prob_list = []\n",
    "    val_prob_list = []\n",
    "    val_pred_list = []\n",
    "    for i in range(len(val_data)):\n",
    "        # prob_list = list(torch.softmax(torch.from_numpy(model_outputs[i]), axis=0)[:,1])\n",
    "        prob_list = torch.softmax(torch.from_numpy(model_outputs[i]), axis=0)\n",
    "        #print(\"Prob List: \", prob_list, type(prob_list))\n",
    "\n",
    "        extracted_prob_list = []\n",
    "        for i in range(len(prob_list)):\n",
    "            extracted_prob_list.append(float(prob_list[i]))\n",
    "\n",
    "        #print(\"Extracted Prob List: \", extracted_prob_list)\n",
    "        # find max one in each submatrix of length 3\n",
    "        max_proba = max(extracted_prob_list)\n",
    "\n",
    "        # identify model prediction based on location of max_proba within extracted_prob_list\n",
    "        if (extracted_prob_list[0] == max_proba):\n",
    "            val_pred_list.append(0)\n",
    "        elif (extracted_prob_list[1] == max_proba):\n",
    "            val_pred_list.append(1)\n",
    "        else:\n",
    "            val_pred_list.append(2)\n",
    "\n",
    "        max_prob_list.append(max_proba)\n",
    "        val_prob_list.append(extracted_prob_list)\n",
    "    \n",
    "    cw_probs = pd.DataFrame(columns = [\"PatientID\", \"Prob\", \"Pred\"])\n",
    "    cw_probs[\"PatientID\"] = val_data[\"PatientID\"]\n",
    "    cw_probs[\"Prob\"] = max_prob_list\n",
    "    cw_probs[\"Pred\"] = val_pred_list\n",
    "    cw_probs.to_csv(trial_dir + \"/sequence_probabilities{}.csv\".format(trial.number))\n",
    "\n",
    "    # compute metrics\n",
    "    # print(\"Shapes of Y-True and Y-Pred\", val_data[\"labels\"].shape, cw_probs[\"Prob\"].shape) \n",
    "    best_auc = sk.roc_auc_score(val_data[\"labels\"].to_list(), val_prob_list, multi_class = \"ovr\", average = \"weighted\")\n",
    "    # best_auc = get_auc(val_prob_list, val_data[\"labels\"])\n",
    "    # best_acc, best_threshold = get_best_acc(cw_probs, val_data)\n",
    "    best_acc = sk.accuracy_score(val_data[\"labels\"].to_list(), cw_probs[\"Pred\"].to_list())\n",
    "    print(\">>> {}: Current AUC: {}\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime()), best_auc))\n",
    "    print(\">>> {}: Current ACC: {}\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime()), best_acc))\n",
    "    #print(\">>> {}: Threshold for Validation Accuracy: {}\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime()), best_threshold))\n",
    "    print(\">>> {}: Start Training Time\\n\".format(time.strftime(\"%H:%M:%S\", start_time)))\n",
    "    print(\">>> {}: Finish Training Time\\n\".format(time.strftime(\"%H:%M:%S\", time.localtime())))\n",
    "\n",
    "    return best_acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# add stream handler of stdout to show the messages\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# unique identifier of the study\n",
    "study_name = \"slat-study\" \n",
    "\n",
    "# create study database\n",
    "storage_name = \"sqlite:///{}.db\".format(\"Storage/Bert/Results/\" + study_name)\n",
    "study = optuna.create_study(direction = \"maximize\", sampler = TPESampler(seed = 1234, multivariate = True), study_name = study_name, storage = storage_name, load_if_exists = True)\n",
    "study.optimize(objective, n_trials = 20, gc_after_trial = True)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"\\nStudy Statistics:\")\n",
    "print(\"- Finished Trials: \", len(study.trials))\n",
    "print(\"- Pruned Trials: \", len(pruned_trials))\n",
    "print(\"- Complete Trials: \", len(complete_trials))\n",
    "\n",
    "print(\"\\nBest Trial:\")\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"- Number: \", best_trial.number)\n",
    "print(\"- Value: \", best_trial.value)\n",
    "print(\"- Hyperparameters: \")\n",
    "\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"   - {}: {}\".format(key, value))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/optuna/samplers/_tpe/sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2021-09-06 09:25:41,339]\u001b[0m Using an existing study with name 'slat-study' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using an existing study with name 'slat-study' instead of creating a new one.\n",
      "\n",
      "-------- TRIAL #15 --------\n",
      "\n",
      ">>> 09:25:41: Preparing Data\n",
      "\n",
      "\n",
      ">>> 09:25:41: Defining Model\n",
      "\n",
      "- Learning Rate: 2.3253948332153446e-05\n",
      "- Adam Epsilon: 5.179831195176861e-06\n",
      "- Training Epochs: 3\n",
      "- Early Stopping Patience: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 09:25:44: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de1999ea2f764a2e9783c83ba47601b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d28755031d84956aa92b14d2aed0b77"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "873f7d30053a4c449505bdbdc1f9632f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce9559ee09904f8ba2b09fa703323832"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8459588487627712, 'eval_loss': 0.35998507888837794}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "242559b1bd6b4950970cd20a88b0bb13"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "542dc5d71db54255a98560ccfaaea047"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8695427891205677, 'eval_loss': 0.3057558276187414}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f85fe716cd441a7b7f866d761fa3839"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcd9c62c78004d5db9693875ad63e2a2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8645777834427238, 'eval_loss': 0.3686744125410058}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 1\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "daa30b305e8342d58130ae6588f9a5a4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8500776064840067, 'eval_loss': 0.35360427491966334}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_15.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 09:59:41: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d2dc659a82545b8af8f30bc33a89267"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "159af4f9c47a48b0854e7dd0796fbb2f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8500776064840067, 'eval_loss': 0.35360427491966334}\n",
      "\u001b[32m[I 2021-09-06 10:00:02,302]\u001b[0m Trial 15 finished with value: 0.909221902017291 and parameters: {'learning_rate': 2.3253948332153446e-05, 'adam_epilson': 5.179831195176861e-06, 'num_train_epochs': 3, 'early_stopping_patience': 1}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 10:00:02: Get Sequence Probabilities\n",
      "\n",
      ">>> 10:00:02: Current AUC: 0.987457090339034\n",
      "\n",
      ">>> 10:00:02: Current ACC: 0.909221902017291\n",
      "\n",
      ">>> 09:25:41: Start Training Time\n",
      "\n",
      ">>> 10:00:02: Finish Training Time\n",
      "\n",
      "Trial 15 finished with value: 0.909221902017291 and parameters: {'learning_rate': 2.3253948332153446e-05, 'adam_epilson': 5.179831195176861e-06, 'num_train_epochs': 3, 'early_stopping_patience': 1}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #16 --------\n",
      "\n",
      ">>> 10:00:02: Preparing Data\n",
      "\n",
      "\n",
      ">>> 10:00:02: Defining Model\n",
      "\n",
      "- Learning Rate: 9.272030580359681e-05\n",
      "- Adam Epsilon: 7.82420326054716e-07\n",
      "- Training Epochs: 2\n",
      "- Early Stopping Patience: 3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 10:00:04: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3edb9cd287c34b1c816d4af122214aed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e87f5cffe6c424695df6e6219d4c964"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72bf725906c54f96b8af74b3127af631"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdcdea144f3b4cf9ad1633a931e4040d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8360645529092684, 'eval_loss': 0.47070251662155677}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05196950773847eb9054773db4641f21"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75525e50bb314164b7727a4c73bccfa4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8644108709992477, 'eval_loss': 0.2964124720672081}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_16.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 10:22:37: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0491be27596c4795ac7d8dc5af9d85e6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06af2988610a432a8b02ea651f2bd2c7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8644108709992477, 'eval_loss': 0.2964124720672081}\n",
      "\u001b[32m[I 2021-09-06 10:23:00,479]\u001b[0m Trial 16 finished with value: 0.9164265129682997 and parameters: {'learning_rate': 9.272030580359681e-05, 'adam_epilson': 7.82420326054716e-07, 'num_train_epochs': 2, 'early_stopping_patience': 3}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 10:23:00: Get Sequence Probabilities\n",
      "\n",
      ">>> 10:23:00: Current AUC: 0.9809571719565615\n",
      "\n",
      ">>> 10:23:00: Current ACC: 0.9164265129682997\n",
      "\n",
      ">>> 10:00:02: Start Training Time\n",
      "\n",
      ">>> 10:23:00: Finish Training Time\n",
      "\n",
      "Trial 16 finished with value: 0.9164265129682997 and parameters: {'learning_rate': 9.272030580359681e-05, 'adam_epilson': 7.82420326054716e-07, 'num_train_epochs': 2, 'early_stopping_patience': 3}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #17 --------\n",
      "\n",
      ">>> 10:23:00: Preparing Data\n",
      "\n",
      "\n",
      ">>> 10:23:00: Defining Model\n",
      "\n",
      "- Learning Rate: 9.964962382649844e-05\n",
      "- Adam Epsilon: 1.1317996951007706e-06\n",
      "- Training Epochs: 3\n",
      "- Early Stopping Patience: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 10:23:02: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3f5026aed2a404aa02f083c29794f50"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7131a0a1d7c6497ba7310e085bf13b17"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2a47c208c6d4153b63cfb0bfd4cf120"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8315a5209dcc47db8e5ded5d915ad352"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8176325100465327, 'eval_loss': 0.447599904290561}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "535186b3aa9f4e7b83d817c45bc1ee40"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fddedf5bbbb047c0b0b8b2b21b753175"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8428333840252515, 'eval_loss': 0.3539542960024428}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f5012bfbc0f4747857a0bac64431499"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc5d434222b1469dbbaf22d3b35ee738"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.856578551714867, 'eval_loss': 0.31879039468436404}\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dffd0fb01e8f4679936f75f2bcc986c8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8606960900960889, 'eval_loss': 0.28777324194195625}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_17.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 10:57:09: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cba165b2828c4283bbb78fb56e173750"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55be105529864a05b5090ddee18026cb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8606960900960889, 'eval_loss': 0.28777324194195625}\n",
      "\u001b[32m[I 2021-09-06 10:57:32,525]\u001b[0m Trial 17 finished with value: 0.9135446685878963 and parameters: {'learning_rate': 9.964962382649844e-05, 'adam_epilson': 1.1317996951007706e-06, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 10:57:32: Get Sequence Probabilities\n",
      "\n",
      ">>> 10:57:32: Current AUC: 0.9757027444432944\n",
      "\n",
      ">>> 10:57:32: Current ACC: 0.9135446685878963\n",
      "\n",
      ">>> 10:23:00: Start Training Time\n",
      "\n",
      ">>> 10:57:32: Finish Training Time\n",
      "\n",
      "Trial 17 finished with value: 0.9135446685878963 and parameters: {'learning_rate': 9.964962382649844e-05, 'adam_epilson': 1.1317996951007706e-06, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #18 --------\n",
      "\n",
      ">>> 10:57:32: Preparing Data\n",
      "\n",
      "\n",
      ">>> 10:57:32: Defining Model\n",
      "\n",
      "- Learning Rate: 2.660982629344484e-05\n",
      "- Adam Epsilon: 3.7512264002029025e-08\n",
      "- Training Epochs: 2\n",
      "- Early Stopping Patience: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 10:57:34: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65b9ca13703f4422b19b30fc79fc04ea"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac727d29eef14674b37d502f14c2e47b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83be4bf480b64c3d95df9a1e5ae5e127"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "baded18716fb424284e3f096d80a6266"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8676032763441391, 'eval_loss': 0.3677904372927786}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3268e7c7c88d4e8f9e94158e7fea2989"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b5887def5a44301b45da93964e734af"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8646482749400378, 'eval_loss': 0.27947936181364386}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_18.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 11:20:16: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "476d79da23c747edae955777555618b2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8406d687bcc34b4db0b72b14dd5c9457"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8646482749400378, 'eval_loss': 0.27947936181364386}\n",
      "\u001b[32m[I 2021-09-06 11:20:39,426]\u001b[0m Trial 18 finished with value: 0.9178674351585014 and parameters: {'learning_rate': 2.660982629344484e-05, 'adam_epilson': 3.7512264002029025e-08, 'num_train_epochs': 2, 'early_stopping_patience': 1}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 11:20:39: Get Sequence Probabilities\n",
      "\n",
      ">>> 11:20:39: Current AUC: 0.9870058343829111\n",
      "\n",
      ">>> 11:20:39: Current ACC: 0.9178674351585014\n",
      "\n",
      ">>> 10:57:32: Start Training Time\n",
      "\n",
      ">>> 11:20:39: Finish Training Time\n",
      "\n",
      "Trial 18 finished with value: 0.9178674351585014 and parameters: {'learning_rate': 2.660982629344484e-05, 'adam_epilson': 3.7512264002029025e-08, 'num_train_epochs': 2, 'early_stopping_patience': 1}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #19 --------\n",
      "\n",
      ">>> 11:20:39: Preparing Data\n",
      "\n",
      "\n",
      ">>> 11:20:39: Defining Model\n",
      "\n",
      "- Learning Rate: 2.478655195871051e-08\n",
      "- Adam Epsilon: 1.8639103000924185e-08\n",
      "- Training Epochs: 1\n",
      "- Early Stopping Patience: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 11:20:41: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a6d919dfefc4165a6d9f18f9371d4ed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0691d3a9bd414ea08c3e727356b2acce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49a17cc4073641d89ced58c031eb6ee2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ceb6f8c06a2406783b30222f09e14fc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'eval_loss': 0.9697079713317169}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_19.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 11:32:03: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8277cb9c59b541f4a7673013c5ec01e6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c01900a8ccb349c7bccd6716db95c8ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'eval_loss': 0.9697079713317169}\n",
      "\u001b[32m[I 2021-09-06 11:32:26,353]\u001b[0m Trial 19 finished with value: 0.5259365994236311 and parameters: {'learning_rate': 2.478655195871051e-08, 'adam_epilson': 1.8639103000924185e-08, 'num_train_epochs': 1, 'early_stopping_patience': 1}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 11:32:26: Get Sequence Probabilities\n",
      "\n",
      ">>> 11:32:26: Current AUC: 0.7165658761656053\n",
      "\n",
      ">>> 11:32:26: Current ACC: 0.5259365994236311\n",
      "\n",
      ">>> 11:20:39: Start Training Time\n",
      "\n",
      ">>> 11:32:26: Finish Training Time\n",
      "\n",
      "Trial 19 finished with value: 0.5259365994236311 and parameters: {'learning_rate': 2.478655195871051e-08, 'adam_epilson': 1.8639103000924185e-08, 'num_train_epochs': 1, 'early_stopping_patience': 1}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #20 --------\n",
      "\n",
      ">>> 11:32:26: Preparing Data\n",
      "\n",
      "\n",
      ">>> 11:32:26: Defining Model\n",
      "\n",
      "- Learning Rate: 2.920735249891083e-06\n",
      "- Adam Epsilon: 2.6230083765667476e-06\n",
      "- Training Epochs: 2\n",
      "- Early Stopping Patience: 3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 11:32:28: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f783b9b78074c918e24cf1738567e30"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "332728177f944b6fbdc40076eefe6a8d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81fdd3a7fc724bab847a0ccf76ffa7bc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f5570f34d164d249baf138d5c9394d6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7738119759594191, 'eval_loss': 0.43575980745512866}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea75751e947f4450a484207d51e6003f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad29ef4a763f4f8f87913aa87dc6de2b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7931451453770462, 'eval_loss': 0.43729386384459745}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_20.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 11:54:58: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dcaaae19ec74a6e8c5695547b57789e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5f992e71b2d4fbb8e1edc40179c602b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7931451453770462, 'eval_loss': 0.43729386384459745}\n",
      "\u001b[32m[I 2021-09-06 11:55:22,337]\u001b[0m Trial 20 finished with value: 0.8731988472622478 and parameters: {'learning_rate': 2.920735249891083e-06, 'adam_epilson': 2.6230083765667476e-06, 'num_train_epochs': 2, 'early_stopping_patience': 3}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 11:55:22: Get Sequence Probabilities\n",
      "\n",
      ">>> 11:55:22: Current AUC: 0.9614324518429661\n",
      "\n",
      ">>> 11:55:22: Current ACC: 0.8731988472622478\n",
      "\n",
      ">>> 11:32:26: Start Training Time\n",
      "\n",
      ">>> 11:55:22: Finish Training Time\n",
      "\n",
      "Trial 20 finished with value: 0.8731988472622478 and parameters: {'learning_rate': 2.920735249891083e-06, 'adam_epilson': 2.6230083765667476e-06, 'num_train_epochs': 2, 'early_stopping_patience': 3}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #21 --------\n",
      "\n",
      ">>> 11:55:22: Preparing Data\n",
      "\n",
      "\n",
      ">>> 11:55:22: Defining Model\n",
      "\n",
      "- Learning Rate: 2.359720345321485e-06\n",
      "- Adam Epsilon: 9.996366669466755e-05\n",
      "- Training Epochs: 3\n",
      "- Early Stopping Patience: 3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 11:55:24: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "426bac4b96224f259e7617e8fa53b002"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce3350e1f7bf45d19557a059850a6223"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0ecc6e77d814a8ebb82390cd6c5719f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16d46df3d82b48328bc9db6cb8dddc35"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.6267114658745542, 'eval_loss': 0.5447068488460848}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28229abad6ce4125b82f5f202be978dd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc3892ea38df438db38566ebb4364226"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7151631296776112, 'eval_loss': 0.4715135947041128}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f98330a2f74d4af3b8d584112c91f4eb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18afb9acc96241b6bd775235d0b8fa76"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7151007426111852, 'eval_loss': 0.46186374795847923}\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb2b4463c8124cdeaf34ec49f7c5d148"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7260927944666324, 'eval_loss': 0.45222556454011764}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_21.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 12:29:39: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5aaad2a227e1450cb331bf5a3d9641cf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14b3b8773d444c6cb750932794fbb902"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7260927944666324, 'eval_loss': 0.45222556454011764}\n",
      "\u001b[32m[I 2021-09-06 12:30:03,041]\u001b[0m Trial 21 finished with value: 0.8328530259365994 and parameters: {'learning_rate': 2.359720345321485e-06, 'adam_epilson': 9.996366669466755e-05, 'num_train_epochs': 3, 'early_stopping_patience': 3}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 12:30:02: Get Sequence Probabilities\n",
      "\n",
      ">>> 12:30:03: Current AUC: 0.9447438405934814\n",
      "\n",
      ">>> 12:30:03: Current ACC: 0.8328530259365994\n",
      "\n",
      ">>> 11:55:22: Start Training Time\n",
      "\n",
      ">>> 12:30:03: Finish Training Time\n",
      "\n",
      "Trial 21 finished with value: 0.8328530259365994 and parameters: {'learning_rate': 2.359720345321485e-06, 'adam_epilson': 9.996366669466755e-05, 'num_train_epochs': 3, 'early_stopping_patience': 3}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #22 --------\n",
      "\n",
      ">>> 12:30:03: Preparing Data\n",
      "\n",
      "\n",
      ">>> 12:30:03: Defining Model\n",
      "\n",
      "- Learning Rate: 4.4729180145319904e-05\n",
      "- Adam Epsilon: 3.917636609396379e-05\n",
      "- Training Epochs: 3\n",
      "- Early Stopping Patience: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 12:30:05: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e902fd54a00c442fb0feefd3dd9b5c0e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9ce7aab0d0d4a338515b79ca8ca38a9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebc81b533ee5448394112d56af387b8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1065f844329f403da21a4af5c48be538"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.851039806366591, 'eval_loss': 0.3637489655922199}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0aa7ea4f46af44288eb21450ebf1cb25"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "903b34ba4bea4be991c34d24e41d310c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8852443707156854, 'eval_loss': 0.26824407536407996}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5729f35d804474d97b53b12ea3ffabf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "209957080ebf40db8b0ceafed8754085"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8739113968626494, 'eval_loss': 0.3107228734712491}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 2\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a79cd3fc1cd54bfca8bd9e5f8957cdaf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.879540974025724, 'eval_loss': 0.29862670240731076}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_22.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 13:04:18: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bb5e75e22fe4f03bdccbc7e6ed0c9e7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ad58b0f92634e7ea61f4f9a6a946588"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.879540974025724, 'eval_loss': 0.29862670240731076}\n",
      "\u001b[32m[I 2021-09-06 13:04:41,924]\u001b[0m Trial 22 finished with value: 0.9265129682997119 and parameters: {'learning_rate': 4.4729180145319904e-05, 'adam_epilson': 3.917636609396379e-05, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 13:04:41: Get Sequence Probabilities\n",
      "\n",
      ">>> 13:04:41: Current AUC: 0.9883149848972057\n",
      "\n",
      ">>> 13:04:41: Current ACC: 0.9265129682997119\n",
      "\n",
      ">>> 12:30:03: Start Training Time\n",
      "\n",
      ">>> 13:04:41: Finish Training Time\n",
      "\n",
      "Trial 22 finished with value: 0.9265129682997119 and parameters: {'learning_rate': 4.4729180145319904e-05, 'adam_epilson': 3.917636609396379e-05, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #23 --------\n",
      "\n",
      ">>> 13:04:42: Preparing Data\n",
      "\n",
      "\n",
      ">>> 13:04:42: Defining Model\n",
      "\n",
      "- Learning Rate: 2.561091114086183e-08\n",
      "- Adam Epsilon: 1.5652121859194013e-08\n",
      "- Training Epochs: 2\n",
      "- Early Stopping Patience: 3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 13:04:44: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a9af65aa3f54c07afab5b0a0d8bfac9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a492f3820c3438e9497387aff13e6fa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1686d55c089e48fc84cd0638ab0d8794"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef950c853d6d46f2b14feafb1bd1fc39"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'eval_loss': 0.9614071900817169}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c464619ee1c44197b3f8a4ac9d05496c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "636a26c839e84a9fa7ae781d96e82c59"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'eval_loss': 0.9529997726966595}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_23.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 13:27:19: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9369147a3454404dbdc981479f98e7da"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdc3b33cd41e4f8c95bcf4624a77c00c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'eval_loss': 0.9529997726966595}\n",
      "\u001b[32m[I 2021-09-06 13:27:43,328]\u001b[0m Trial 23 finished with value: 0.5259365994236311 and parameters: {'learning_rate': 2.561091114086183e-08, 'adam_epilson': 1.5652121859194013e-08, 'num_train_epochs': 2, 'early_stopping_patience': 3}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 13:27:43: Get Sequence Probabilities\n",
      "\n",
      ">>> 13:27:43: Current AUC: 0.7684939948549364\n",
      "\n",
      ">>> 13:27:43: Current ACC: 0.5259365994236311\n",
      "\n",
      ">>> 13:04:42: Start Training Time\n",
      "\n",
      ">>> 13:27:43: Finish Training Time\n",
      "\n",
      "Trial 23 finished with value: 0.5259365994236311 and parameters: {'learning_rate': 2.561091114086183e-08, 'adam_epilson': 1.5652121859194013e-08, 'num_train_epochs': 2, 'early_stopping_patience': 3}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #24 --------\n",
      "\n",
      ">>> 13:27:43: Preparing Data\n",
      "\n",
      "\n",
      ">>> 13:27:43: Defining Model\n",
      "\n",
      "- Learning Rate: 1.5454548042997283e-05\n",
      "- Adam Epsilon: 8.566176825278376e-05\n",
      "- Training Epochs: 3\n",
      "- Early Stopping Patience: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 13:27:45: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9272c15b3d1f4f7786bcf335ab4d6d2f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a13d05d169c4d66b3f65cdea4bafd54"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e0270a93e68476383e51e1c26e27aff"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4501ac73a3c545d5b3022928665a26f4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7910497793850809, 'eval_loss': 0.47258988194081974}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9dfb7aa7ee544e1cad6099413ac7b024"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca5c8b026a0b4219bebed1425d5e7839"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8333935258273405, 'eval_loss': 0.39858346423883545}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d69058e060944f3b7a6d7156afb7aab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "336785b52f704921a255d6fcec864968"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8406106146290592, 'eval_loss': 0.4227320627234448}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 2\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3542d4dbe074f38a9ab1b568d9384a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8376933824997106, 'eval_loss': 0.40373977847482967}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_24.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 14:01:58: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6a28af7ea9a4208a0270b709ddecb48"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4b99dafd4f444af85d4bfaed404b2c6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8376933824997106, 'eval_loss': 0.40373977847482967}\n",
      "\u001b[32m[I 2021-09-06 14:02:22,456]\u001b[0m Trial 24 finished with value: 0.9005763688760807 and parameters: {'learning_rate': 1.5454548042997283e-05, 'adam_epilson': 8.566176825278376e-05, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 14:02:22: Get Sequence Probabilities\n",
      "\n",
      ">>> 14:02:22: Current AUC: 0.979920571927459\n",
      "\n",
      ">>> 14:02:22: Current ACC: 0.9005763688760807\n",
      "\n",
      ">>> 13:27:43: Start Training Time\n",
      "\n",
      ">>> 14:02:22: Finish Training Time\n",
      "\n",
      "Trial 24 finished with value: 0.9005763688760807 and parameters: {'learning_rate': 1.5454548042997283e-05, 'adam_epilson': 8.566176825278376e-05, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #25 --------\n",
      "\n",
      ">>> 14:02:22: Preparing Data\n",
      "\n",
      "\n",
      ">>> 14:02:22: Defining Model\n",
      "\n",
      "- Learning Rate: 6.399573419599201e-05\n",
      "- Adam Epsilon: 8.358075530495174e-05\n",
      "- Training Epochs: 3\n",
      "- Early Stopping Patience: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 14:02:24: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "734f136e9ace40bfa1fad5fb34030b09"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43a8ae6fa863417fb91b50eb2559f3a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dd61ea25fca4609aa8c4c2badf7b54c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b64679b6bb848fab4e1ca2dde30255c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8492510126699169, 'eval_loss': 0.3670082010071853}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d71872a9d8994a60b9f7d6c18a9fae89"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bbb32740fcf445dba22d3e5f173be46"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8699800355220089, 'eval_loss': 0.28199116971300936}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4eef246967f84e77b7ae7eb5993460ef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "834e4d707102459abf627d69c78ba29b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8770998868417814, 'eval_loss': 0.3319356801181004}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 2\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7aebd29ef44d487da5891699d6f90eef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8742904177154086, 'eval_loss': 0.3006961606014734}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_25.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 14:36:37: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a27f5ea0d3ac476581ce4b5ca64887d8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d465cf280cb7491b9b9993722e7a093d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8742904177154086, 'eval_loss': 0.3006961606014734}\n",
      "\u001b[32m[I 2021-09-06 14:37:02,257]\u001b[0m Trial 25 finished with value: 0.9236311239193083 and parameters: {'learning_rate': 6.399573419599201e-05, 'adam_epilson': 8.358075530495174e-05, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 14:37:02: Get Sequence Probabilities\n",
      "\n",
      ">>> 14:37:02: Current AUC: 0.9888553624622908\n",
      "\n",
      ">>> 14:37:02: Current ACC: 0.9236311239193083\n",
      "\n",
      ">>> 14:02:22: Start Training Time\n",
      "\n",
      ">>> 14:37:02: Finish Training Time\n",
      "\n",
      "Trial 25 finished with value: 0.9236311239193083 and parameters: {'learning_rate': 6.399573419599201e-05, 'adam_epilson': 8.358075530495174e-05, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #26 --------\n",
      "\n",
      ">>> 14:37:02: Preparing Data\n",
      "\n",
      "\n",
      ">>> 14:37:02: Defining Model\n",
      "\n",
      "- Learning Rate: 4.3237680408766715e-08\n",
      "- Adam Epsilon: 2.1962679832144807e-05\n",
      "- Training Epochs: 3\n",
      "- Early Stopping Patience: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 14:37:04: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7788160a7b9142f48a1ebbfac70a14a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1be811cd674145adb7cc52d6d1e1cd3e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d232ab5f795b431eb1dcb4c36a5210ff"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e251ba0cff5040039cf2f784b8b66386"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.0, 'eval_loss': 0.9587942539960489}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d4f560507974ffe9498c7cc23569015"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38dd8acc79b94c4bb83589bc6fca1e09"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.04237320884104599, 'eval_loss': 0.938555838047773}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a56c1415e662493992ea0844884e59e3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "852b73166ef645eca2ba410e9ab7d717"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.04237320884104599, 'eval_loss': 0.9373793327945402}\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50c18710854c4ec1ac9bdb51f91c19f1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.04237320884104599, 'eval_loss': 0.93206787109375}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_26.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 15:11:25: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df18f15256ed4224b24d2acea3068f2c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "815fad6f41014763954978d75474f72f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.04237320884104599, 'eval_loss': 0.93206787109375}\n",
      "\u001b[32m[I 2021-09-06 15:11:49,643]\u001b[0m Trial 26 finished with value: 0.5273775216138329 and parameters: {'learning_rate': 4.3237680408766715e-08, 'adam_epilson': 2.1962679832144807e-05, 'num_train_epochs': 3, 'early_stopping_patience': 1}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 15:11:49: Get Sequence Probabilities\n",
      "\n",
      ">>> 15:11:49: Current AUC: 0.8110726492993022\n",
      "\n",
      ">>> 15:11:49: Current ACC: 0.5273775216138329\n",
      "\n",
      ">>> 14:37:02: Start Training Time\n",
      "\n",
      ">>> 15:11:49: Finish Training Time\n",
      "\n",
      "Trial 26 finished with value: 0.5273775216138329 and parameters: {'learning_rate': 4.3237680408766715e-08, 'adam_epilson': 2.1962679832144807e-05, 'num_train_epochs': 3, 'early_stopping_patience': 1}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #27 --------\n",
      "\n",
      ">>> 15:11:49: Preparing Data\n",
      "\n",
      "\n",
      ">>> 15:11:49: Defining Model\n",
      "\n",
      "- Learning Rate: 4.025335798567959e-06\n",
      "- Adam Epsilon: 3.128773758142213e-06\n",
      "- Training Epochs: 3\n",
      "- Early Stopping Patience: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 15:11:52: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7eb1f271742a4778ad1396f2274b4d4a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d14e788140de404da3d5b133cf69a135"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "249d295c3d4a4354b5a8aa98c3d28318"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76d50e03968e46fdaad862ba328cebc2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.7916056192633907, 'eval_loss': 0.45641659046041555}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d11c03b50a61462fbc1a52e931da5801"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40fefec23e0e41a58c41367abd3ac82c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.821358860905201, 'eval_loss': 0.42163711580736885}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49169e581f644b2aa368b1f06e21891f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0772aac74eff41798d5e8f026b8ee1c5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8175646322636638, 'eval_loss': 0.44134882400775777}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 2\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c604f9c83cb24653a5505a5804fbb2ed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8244941055525482, 'eval_loss': 0.4384940739335685}\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to Storage/Bert/Results/trial_27.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 15:46:08: Started Evaluation on Validation Set\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaa3d34333a84d8f8961de4a09a1ba1b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Evaluation:   0%|          | 0/174 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a99d4ca597bc457389e8ab908dd222fe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.8244941055525482, 'eval_loss': 0.4384940739335685}\n",
      "\u001b[32m[I 2021-09-06 15:46:32,966]\u001b[0m Trial 27 finished with value: 0.8919308357348703 and parameters: {'learning_rate': 4.025335798567959e-06, 'adam_epilson': 3.128773758142213e-06, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> 15:46:32: Get Sequence Probabilities\n",
      "\n",
      ">>> 15:46:32: Current AUC: 0.975311501096442\n",
      "\n",
      ">>> 15:46:32: Current ACC: 0.8919308357348703\n",
      "\n",
      ">>> 15:11:49: Start Training Time\n",
      "\n",
      ">>> 15:46:32: Finish Training Time\n",
      "\n",
      "Trial 27 finished with value: 0.8919308357348703 and parameters: {'learning_rate': 4.025335798567959e-06, 'adam_epilson': 3.128773758142213e-06, 'num_train_epochs': 3, 'early_stopping_patience': 2}. Best is trial 13 with value: 0.9279538904899135.\n",
      "\n",
      "-------- TRIAL #28 --------\n",
      "\n",
      ">>> 15:46:33: Preparing Data\n",
      "\n",
      "\n",
      ">>> 15:46:33: Defining Model\n",
      "\n",
      "- Learning Rate: 8.073120236427379e-05\n",
      "- Adam Epsilon: 3.9441532970755586e-05\n",
      "- Training Epochs: 2\n",
      "- Early Stopping Patience: 3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      ">>> 15:46:35: Started Training\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/7669 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45c33734da874b77ab8172da94715e17"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_512_3_2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa217b8e3cb44d1c9a4edc03c939cb76"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/959 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cc8cd71858d4c76b3ca8ffda7d432dc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_2738224/1179753294.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstorage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sqlite:///{}.db\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Storage/Bert/Results/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1234\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultivariate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_if_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ipykernel_2738224/2482318221.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     model.train_model(\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0meval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         global_step, training_details = self.train(\n\u001b[0m\u001b[1;32m    636\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/mindds/2/projects/apoe-dl/apoe_slat/apoe-dl-env/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, output_dir, multi_label, show_running_loss, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('apoe-dl-env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "b0168968bb7ecfa78684047e3c95d55595c46869da584ba4da41f68e310286ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
