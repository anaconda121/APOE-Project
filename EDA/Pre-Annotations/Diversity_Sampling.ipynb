{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandasgui import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# General\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from datetime import date\n",
    "import warnings\n",
    "current_date = date.today()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\BigDataSets\\Regex_match\\FINAL\\summary_stats_7_14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\BigDataSets\\Regex_match\\FINAL\\MASTER_7_14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\EDA\\Getting_Data\\keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_KEYWORD_MATCHES = list(total[\"Total_Count\"].unique())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diverse_df = pd.DataFrame(columns = list(matches.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 5000 / TOTAL_KEYWORD_MATCHES\n",
    "\n",
    "int(math.ceil(24 * percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['dementia', 'cognition', 'memory', 'mmse', 'moca', 'alzheimer', 'cognitive impairment', 'mci', 'cerebellar', 'neurocognitive', 'lewy', \"pick's\",  'corticobasal', 'cerebral', 'cerebrovascular', 'amnesia', 'ad', 'lbd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_sampling(SEQ_COUNT):\n",
    "    # Constant declarations\n",
    "    diverse_df = pd.DataFrame(columns = list(matches.columns))\n",
    "\n",
    "    for word in (keywords):\n",
    "        # getting subset of dataframe that contains sequence with keyword match\n",
    "        contains = matches['padded_regex_match'].str.contains(str(word))\n",
    "        filtered = matches[contains]\n",
    "        subset = pd.DataFrame(columns = list(matches.columns))  \n",
    "        # calculating percent that will be taken from each set of keyword matches\n",
    "        percent = SEQ_COUNT / TOTAL_KEYWORD_MATCHES\n",
    "        # getting number of matches to take from subset of keyword matches\n",
    "        take = int(math.ceil(len(filtered) * percent))\n",
    "        \n",
    "        if (take == 1):\n",
    "            take = 2\n",
    "            \n",
    "        print(\"Word:\", word, \"Take: \", take , \"EMPI: \", len(filtered[\"EMPI\"]), \"Unique EMPI: \", len(filtered[\"EMPI\"].unique()))\n",
    "\n",
    "        if (take <= len(filtered[\"EMPI\"].unique())):\n",
    "            # priortizing getting sequences from unique patients if size of take permits\n",
    "            filtered = filtered.drop_duplicates(subset = \"EMPI\", keep = \"first\")\n",
    "            \n",
    "            unique_empi = diverse_df[\"EMPI\"].unique().tolist()\n",
    "            \n",
    "            filtered[\"in_diverse_df\"] = np.where(filtered[\"EMPI\"].isin(unique_empi), 'Y', 'N')\n",
    "            new_additions = filtered[filtered[\"in_diverse_df\"] == 'N']\n",
    "            new_additions = pd.DataFrame(new_additions, columns = list(matches.columns))\n",
    "            \n",
    "#             print(\"New Additions: \", len(new_additions))\n",
    "            idx = 0\n",
    "            if take <= len(new_additions):\n",
    "                idx = take\n",
    "            else:\n",
    "                idx = new_additions - 1\n",
    "            new_additions = new_additions.iloc[:idx]\n",
    "            subset = subset.append(new_additions)\n",
    "            print(\"Subset After New Additions: \", len(subset), \"Subset Unique EMPI: \", len(subset[\"EMPI\"].unique().tolist()))\n",
    "                    \n",
    "            take -= len(new_additions)\n",
    "            \n",
    "            if (take > 0):\n",
    "                filtered.drop(new_additions.index, axis = 0, inplace = True)\n",
    "\n",
    "                # generating random index numbers for subset\n",
    "                for _ in range(take):\n",
    "                    idx = random.sample(range(0, len(filtered)), take)\n",
    "                    subset = subset.append(pd.DataFrame(filtered.iloc[idx]).T)\n",
    "\n",
    "                print(\"Subset: \", len(subset))\n",
    "        else:\n",
    "            # getting as many unique patient records as possible even if take > len(filtered[\"EMPI\"].unique())\n",
    "            partial_subset = filtered.drop_duplicates(subset = \"EMPI\", keep = \"first\")\n",
    "            print(\"PS: \", len(partial_subset))\n",
    "            subset.append(partial_subset)\n",
    "            take -= len(partial_subset)\n",
    "            filtered.drop(partial_subset.index, axis = 0, inplace = True)\n",
    "\n",
    "            # generating random index numbers for subset\n",
    "            for _ in range(take):\n",
    "                idx = random.sample(range(0, len(filtered)), take)\n",
    "                subset = subset.append(pd.DataFrame(matches.iloc[idx]).T)\n",
    "                #print(len(subset))  \n",
    "\n",
    "        diverse_df = diverse_df.append(subset)\n",
    "        print(\"Unique EMPI: \", len(diverse_df[\"EMPI\"].unique()), \"Len: \", len(diverse_df), \"\\n\")\n",
    "    return diverse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diverse_df = diversity_sampling(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diverse_df = diverse_df.reset_index()\n",
    "diverse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diverse_df[\"PatientID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diverse_df.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\BigDataSets\\Regex_match\\Diversity_Sampling\\5000_sample_7_19.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Keyword Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining summary stats df\n",
    "cols =  ['dementia', 'cognition', 'memory', 'mmse', 'moca', 'alzheimer', 'cognitive impairment', 'mci', 'cerebellar', 'neurocognitive', 'lewy', \"pick's\",  'corticobasal', 'cerebral', 'cerebrovascular', 'amnesia', 'ad', 'lbd']\n",
    "\n",
    "summary_stats_seq  = pd.DataFrame(pd.np.empty((len(diverse_df), len(cols) + 3)) * pd.np.nan) \n",
    "summary_stats_seq.columns = ['EMPI', 'EncounterID', 'NoteID'] + list(cols)\n",
    "summary_stats_seq[\"EMPI\"] = diverse_df[\"EMPI\"].to_list()\n",
    "summary_stats_seq[\"EncounterID\"] = diverse_df[\"PatientEncounterID\"].to_list()\n",
    "summary_stats_seq[\"NoteID\"]  = diverse_df[\"NoteID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(d))):\n",
    "    match_tuples = []\n",
    "    keyword_list = []\n",
    "    \n",
    "\n",
    "    keyword_list = (eval(d['regex_match'][i]))\n",
    "    keyword_list = list(eval(keyword_list))\n",
    "    for z in range(len(keyword_list)):\n",
    "        match_tuples.append((keyword_list[z], 0))\n",
    "\n",
    "    freq = {\"dementia\":0\n",
    "        ,\"cognition\":0\n",
    "        ,\"cognition\":0\n",
    "        ,\"memory\":0\n",
    "        ,\"mmse\":0\n",
    "        ,\"moca\":0\n",
    "        ,\"alzheimer\":0\n",
    "        ,'cognitive impairment':0\n",
    "        ,\"mci\":0\n",
    "        ,\"cerebellar\":0\n",
    "        ,\"neurocognitive\":0\n",
    "        ,\"lewy\":0\n",
    "        ,\"pick's\":0\n",
    "        ,\"corticobasal\":0\n",
    "        ,\"cerebral\":0\n",
    "        ,\"cerebrovascular\":0\n",
    "        ,\"amnesia\":0\n",
    "        ,\"ad\": 0\n",
    "        ,\"lbd\": 0\n",
    "    }\n",
    "\n",
    "    for k, v in match_tuples:   \n",
    "        if (k != ''):\n",
    "            if (k == 'cognitive impairmentcognitiveimpairment' or k == 'cognitiveimpairmentcognitive impairment'):\n",
    "                k = 'cognitive impairment'\n",
    "                freq.update({str(k.lower()):int(freq[k.lower()] + 1)})\n",
    "            else:\n",
    "                freq.update({str(k.lower()):int(freq[k.lower()] + 1)})\n",
    "            \n",
    "    #print(freq.items())\n",
    "    #print(summary_stats[\"dementia\"])\n",
    "    for k, v in freq.items():\n",
    "        #print(str(k.lower()))\n",
    "        summary_stats_seq[str(k.lower())][i] = int(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats_seq.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\BigDataSets\\Regex_match\\Diversity_Sampling\\5000_seqs_7_23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing SLAT Pipeline Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\nlp_annotator-dev\\app\\load_data\\SLAT_production_7_22.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-running keyword matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\EDA\\Getting_Data\\keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[re.compile('\\\\bdementia\\\\b', re.IGNORECASE), re.compile('\\\\bcognition\\\\b', re.IGNORECASE), re.compile('\\\\bmemory\\\\b', re.IGNORECASE), re.compile('\\\\bMMSE\\\\b', re.IGNORECASE), re.compile('\\\\bMOCA\\\\b', re.IGNORECASE), re.compile('\\\\bAlzheimer\\\\b', re.IGNORECASE), re.compile('\\\\bcognitive\\\\s*impairment\\\\b', re.IGNORECASE), re.compile('(?-i:)\\\\bMCI\\\\b'), re.compile('\\\\bcerebellar\\\\b', re.IGNORECASE), re.compile('\\\\bNeurocognitive\\\\b', re.IGNORECASE), re.compile('\\\\blewy\\\\b', re.IGNORECASE), re.compile(\"\\\\bpick's\\\\b\", re.IGNORECASE), re.compile('\\\\bCorticobasal\\\\b', re.IGNORECASE), re.compile('\\\\bcerebral\\\\b', re.IGNORECASE), re.compile('\\\\bcerebrovascular\\\\b', re.IGNORECASE), re.compile('\\\\bamnesia\\\\b', re.IGNORECASE), re.compile('(?-i:)\\\\bAD\\\\b'), re.compile('(?-i:)\\\\bLBD\\\\b')]\n"
     ]
    }
   ],
   "source": [
    "k = regex[\"REGEX\"].to_list()\n",
    "c = regex[\"CASE\"].to_list()\n",
    "p_list = []\n",
    "\n",
    "for i in range(len(k)):\n",
    "    if (c[i] == 0):\n",
    "        p_list.append(re.compile(k[i][5:], re.IGNORECASE))\n",
    "    elif (c[i] == 1):\n",
    "        p_list.append(re.compile(k[i]))\n",
    "print(p_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 279224/279224 [00:43<00:00, 6356.01it/s]\n"
     ]
    }
   ],
   "source": [
    "locations = []\n",
    "\n",
    "for r in tqdm(matches['regex_sent']):\n",
    "    l = []\n",
    "    for p in (p_list):\n",
    "        for match in re.finditer(p, r):\n",
    "            l.append(match.span())\n",
    "    #print(l)\n",
    "    locations.append(l)\n",
    "        \n",
    "matches[\"regex_location\"] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 279224/279224 [00:44<00:00, 6254.89it/s]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for note in tqdm(matches[\"regex_sent\"]):\n",
    "    curr = []\n",
    "    for p in (p_list):\n",
    "        m = list(set(re.findall(p, note)))\n",
    "        m = list(set((m)))\n",
    "        if (m != []):\n",
    "            curr.append(\"\".join(m))\n",
    "    #print(curr)\n",
    "    #print(l)\n",
    "    l.append((curr))\n",
    "\n",
    "matches[\"regex_match\"] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>MRN</th>\n",
       "      <th>EMPI</th>\n",
       "      <th>PatientEncounterID</th>\n",
       "      <th>InpatientNoteTypeDSC</th>\n",
       "      <th>NoteID</th>\n",
       "      <th>NoteCSNID</th>\n",
       "      <th>ContactDTS</th>\n",
       "      <th>NoteTXT</th>\n",
       "      <th>regex_sent</th>\n",
       "      <th>regex_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z6352398</td>\n",
       "      <td>10040002098</td>\n",
       "      <td>100000272</td>\n",
       "      <td>3.242118e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>2370049295</td>\n",
       "      <td>2.338373e+09</td>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"ession alone in the meta-analysis. We discuss...</td>\n",
       "      <td>[dementia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z6352922</td>\n",
       "      <td>200766</td>\n",
       "      <td>100000894</td>\n",
       "      <td>3.181499e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>1916263837</td>\n",
       "      <td>1.871982e+09</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\" ------- sis over her R bra strap, which was ...</td>\n",
       "      <td>[dementia, Memory, MOCA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z6353136</td>\n",
       "      <td>10027033512</td>\n",
       "      <td>100001150</td>\n",
       "      <td>3.018789e+09</td>\n",
       "      <td>Discharge Summary</td>\n",
       "      <td>267681869</td>\n",
       "      <td>2.555255e+08</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\" ------- l obstruction ASSOCIATED DIAGNOSES S...</td>\n",
       "      <td>[Dementia, cognitive impairment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z6353461</td>\n",
       "      <td>10040011735</td>\n",
       "      <td>100001521</td>\n",
       "      <td>3.172504e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>1682366001</td>\n",
       "      <td>1.631850e+09</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\" -------  (156 lb) 09/19/17 71.4 kg (157 lb 6...</td>\n",
       "      <td>[dementia, Cognition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z6353764</td>\n",
       "      <td>10040014499</td>\n",
       "      <td>100001873</td>\n",
       "      <td>3.165983e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>1853759390</td>\n",
       "      <td>1.807703e+09</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"ut answer. Optho notes from recent outpatient...</td>\n",
       "      <td>[dementia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279219</th>\n",
       "      <td>Z16320629</td>\n",
       "      <td>10127549029</td>\n",
       "      <td>113705759</td>\n",
       "      <td>3.285425e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>3960511043</td>\n",
       "      <td>3.943607e+09</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"''she took a break' and wants to discuss with...</td>\n",
       "      <td>[memory]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279220</th>\n",
       "      <td>Z16320629</td>\n",
       "      <td>10127549029</td>\n",
       "      <td>113705759</td>\n",
       "      <td>3.305416e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>4585859437</td>\n",
       "      <td>4.574134e+09</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"'all of her medications, including aspirin. D...</td>\n",
       "      <td>[memory]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279221</th>\n",
       "      <td>Z16320629</td>\n",
       "      <td>10127549029</td>\n",
       "      <td>113705759</td>\n",
       "      <td>3.327430e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>5203067949</td>\n",
       "      <td>5.224024e+09</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"'Patient, Chart, daughter Olga Mode of contac...</td>\n",
       "      <td>[cognition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279222</th>\n",
       "      <td>Z16320629</td>\n",
       "      <td>10127549029</td>\n",
       "      <td>113705759</td>\n",
       "      <td>3.349755e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>5673786544</td>\n",
       "      <td>5.670392e+09</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"'Patient, Chart, daughter Olga Mode of contac...</td>\n",
       "      <td>[cognition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279223</th>\n",
       "      <td>Z16323433</td>\n",
       "      <td>10127577079</td>\n",
       "      <td>113708529</td>\n",
       "      <td>3.196619e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>1939524875</td>\n",
       "      <td>1.895938e+09</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"'cyanosis or edema. Neurological exam: Nonfoc...</td>\n",
       "      <td>[Cognition]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279224 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PatientID          MRN       EMPI  PatientEncounterID  \\\n",
       "0        Z6352398  10040002098  100000272        3.242118e+09   \n",
       "1        Z6352922       200766  100000894        3.181499e+09   \n",
       "2        Z6353136  10027033512  100001150        3.018789e+09   \n",
       "3        Z6353461  10040011735  100001521        3.172504e+09   \n",
       "4        Z6353764  10040014499  100001873        3.165983e+09   \n",
       "...           ...          ...        ...                 ...   \n",
       "279219  Z16320629  10127549029  113705759        3.285425e+09   \n",
       "279220  Z16320629  10127549029  113705759        3.305416e+09   \n",
       "279221  Z16320629  10127549029  113705759        3.327430e+09   \n",
       "279222  Z16320629  10127549029  113705759        3.349755e+09   \n",
       "279223  Z16323433  10127577079  113708529        3.196619e+09   \n",
       "\n",
       "       InpatientNoteTypeDSC      NoteID     NoteCSNID  ContactDTS  \\\n",
       "0            Progress Notes  2370049295  2.338373e+09  2019-03-14   \n",
       "1            Progress Notes  1916263837  1.871982e+09  2018-03-28   \n",
       "2         Discharge Summary   267681869  2.555255e+08  2015-01-09   \n",
       "3            Progress Notes  1682366001  1.631850e+09  2017-10-03   \n",
       "4            Progress Notes  1853759390  1.807703e+09  2018-02-07   \n",
       "...                     ...         ...           ...         ...   \n",
       "279219       Progress Notes  3960511043  3.943607e+09  2020-04-28   \n",
       "279220       Progress Notes  4585859437  4.574134e+09  2020-09-22   \n",
       "279221       Progress Notes  5203067949  5.224024e+09  2021-01-25   \n",
       "279222       Progress Notes  5673786544  5.670392e+09  2021-04-20   \n",
       "279223       Progress Notes  1939524875  1.895938e+09  2018-04-16   \n",
       "\n",
       "                                                  NoteTXT  \\\n",
       "0       ----------------------------------------------...   \n",
       "1       ----------------------------------------------...   \n",
       "2       ----------------------------------------------...   \n",
       "3       ----------------------------------------------...   \n",
       "4       ----------------------------------------------...   \n",
       "...                                                   ...   \n",
       "279219  ----------------------------------------------...   \n",
       "279220  ----------------------------------------------...   \n",
       "279221  ----------------------------------------------...   \n",
       "279222  ----------------------------------------------...   \n",
       "279223  ----------------------------------------------...   \n",
       "\n",
       "                                               regex_sent  \\\n",
       "0       \"ession alone in the meta-analysis. We discuss...   \n",
       "1       \" ------- sis over her R bra strap, which was ...   \n",
       "2       \" ------- l obstruction ASSOCIATED DIAGNOSES S...   \n",
       "3       \" -------  (156 lb) 09/19/17 71.4 kg (157 lb 6...   \n",
       "4       \"ut answer. Optho notes from recent outpatient...   \n",
       "...                                                   ...   \n",
       "279219  \"''she took a break' and wants to discuss with...   \n",
       "279220  \"'all of her medications, including aspirin. D...   \n",
       "279221  \"'Patient, Chart, daughter Olga Mode of contac...   \n",
       "279222  \"'Patient, Chart, daughter Olga Mode of contac...   \n",
       "279223  \"'cyanosis or edema. Neurological exam: Nonfoc...   \n",
       "\n",
       "                             regex_match  \n",
       "0                             [dementia]  \n",
       "1               [dementia, Memory, MOCA]  \n",
       "2       [Dementia, cognitive impairment]  \n",
       "3                  [dementia, Cognition]  \n",
       "4                             [dementia]  \n",
       "...                                  ...  \n",
       "279219                          [memory]  \n",
       "279220                          [memory]  \n",
       "279221                       [cognition]  \n",
       "279222                       [cognition]  \n",
       "279223                       [Cognition]  \n",
       "\n",
       "[279224 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279000    [Dementia, cognitive impairment, Lewy]\n",
       "Name: regex_match, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(matches[\"regex_match\"].iloc[[279000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"ContactDTS\"] = pd.to_datetime(matches[\"ContactDTS\"]).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['regex_sent'] = matches['regex_sent'].apply(json.dumps)\n",
    "matches['regex_match'] = matches['regex_match'].apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches = matches.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>MRN</th>\n",
       "      <th>EMPI</th>\n",
       "      <th>PatientEncounterID</th>\n",
       "      <th>InpatientNoteTypeDSC</th>\n",
       "      <th>NoteID</th>\n",
       "      <th>NoteCSNID</th>\n",
       "      <th>ContactDTS</th>\n",
       "      <th>NoteTXT</th>\n",
       "      <th>regex_sent</th>\n",
       "      <th>regex_match</th>\n",
       "      <th>regex_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Z6352398</td>\n",
       "      <td>10040002098</td>\n",
       "      <td>100000272</td>\n",
       "      <td>3.242118e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>2370049295</td>\n",
       "      <td>2.338373e+09</td>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\"ession alone in the meta-analysis. We discu...</td>\n",
       "      <td>\"['dementia']\"</td>\n",
       "      <td>[(397, 405)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Z6352922</td>\n",
       "      <td>200766</td>\n",
       "      <td>100000894</td>\n",
       "      <td>3.181499e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>1916263837</td>\n",
       "      <td>1.871982e+09</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\" ------- sis over her R bra strap, which wa...</td>\n",
       "      <td>\"['dementia', 'memory', 'moca']\"</td>\n",
       "      <td>[(256, 264), (561, 569), (217, 223), (513, 519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Z6353136</td>\n",
       "      <td>10027033512</td>\n",
       "      <td>100001150</td>\n",
       "      <td>3.018789e+09</td>\n",
       "      <td>Discharge Summary</td>\n",
       "      <td>267681869</td>\n",
       "      <td>2.555255e+08</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\" ------- l obstruction ASSOCIATED DIAGNOSES...</td>\n",
       "      <td>\"['dementia', 'cognitive impairment']\"</td>\n",
       "      <td>[(180, 188), (627, 635), (398, 418)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Z6353461</td>\n",
       "      <td>10040011735</td>\n",
       "      <td>100001521</td>\n",
       "      <td>3.172504e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>1682366001</td>\n",
       "      <td>1.631850e+09</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\" -------  (156 lb) 09/19/17 71.4 kg (157 lb...</td>\n",
       "      <td>\"['dementia', 'cognition']\"</td>\n",
       "      <td>[(512, 520), (294, 303)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Z6353764</td>\n",
       "      <td>10040014499</td>\n",
       "      <td>100001873</td>\n",
       "      <td>3.165983e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>1853759390</td>\n",
       "      <td>1.807703e+09</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\"ut answer. Optho notes from recent outpatie...</td>\n",
       "      <td>\"['dementia']\"</td>\n",
       "      <td>[(395, 403)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279219</th>\n",
       "      <td>279219</td>\n",
       "      <td>Z16320629</td>\n",
       "      <td>10127549029</td>\n",
       "      <td>113705759</td>\n",
       "      <td>3.285425e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>3960511043</td>\n",
       "      <td>3.943607e+09</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\"''she took a break' and wants to discuss wi...</td>\n",
       "      <td>\"['memory']\"</td>\n",
       "      <td>[(99, 105)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279220</th>\n",
       "      <td>279220</td>\n",
       "      <td>Z16320629</td>\n",
       "      <td>10127549029</td>\n",
       "      <td>113705759</td>\n",
       "      <td>3.305416e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>4585859437</td>\n",
       "      <td>4.574134e+09</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\"'all of her medications, including aspirin....</td>\n",
       "      <td>\"['memory']\"</td>\n",
       "      <td>[(101, 107)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279221</th>\n",
       "      <td>279221</td>\n",
       "      <td>Z16320629</td>\n",
       "      <td>10127549029</td>\n",
       "      <td>113705759</td>\n",
       "      <td>3.327430e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>5203067949</td>\n",
       "      <td>5.224024e+09</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\"'Patient, Chart, daughter Olga Mode of cont...</td>\n",
       "      <td>\"['cognition']\"</td>\n",
       "      <td>[(100, 109)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279222</th>\n",
       "      <td>279222</td>\n",
       "      <td>Z16320629</td>\n",
       "      <td>10127549029</td>\n",
       "      <td>113705759</td>\n",
       "      <td>3.349755e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>5673786544</td>\n",
       "      <td>5.670392e+09</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\"'Patient, Chart, daughter Olga Mode of cont...</td>\n",
       "      <td>\"['cognition']\"</td>\n",
       "      <td>[(100, 109)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279223</th>\n",
       "      <td>279223</td>\n",
       "      <td>Z16323433</td>\n",
       "      <td>10127577079</td>\n",
       "      <td>113708529</td>\n",
       "      <td>3.196619e+09</td>\n",
       "      <td>Progress Notes</td>\n",
       "      <td>1939524875</td>\n",
       "      <td>1.895938e+09</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>\"\\\"'cyanosis or edema. Neurological exam: Nonf...</td>\n",
       "      <td>\"['cognition']\"</td>\n",
       "      <td>[(100, 109)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279224 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  PatientID          MRN       EMPI  PatientEncounterID  \\\n",
       "0            0   Z6352398  10040002098  100000272        3.242118e+09   \n",
       "1            1   Z6352922       200766  100000894        3.181499e+09   \n",
       "2            2   Z6353136  10027033512  100001150        3.018789e+09   \n",
       "3            3   Z6353461  10040011735  100001521        3.172504e+09   \n",
       "4            4   Z6353764  10040014499  100001873        3.165983e+09   \n",
       "...        ...        ...          ...        ...                 ...   \n",
       "279219  279219  Z16320629  10127549029  113705759        3.285425e+09   \n",
       "279220  279220  Z16320629  10127549029  113705759        3.305416e+09   \n",
       "279221  279221  Z16320629  10127549029  113705759        3.327430e+09   \n",
       "279222  279222  Z16320629  10127549029  113705759        3.349755e+09   \n",
       "279223  279223  Z16323433  10127577079  113708529        3.196619e+09   \n",
       "\n",
       "       InpatientNoteTypeDSC      NoteID     NoteCSNID  ContactDTS  \\\n",
       "0            Progress Notes  2370049295  2.338373e+09  2019-03-14   \n",
       "1            Progress Notes  1916263837  1.871982e+09  2018-03-28   \n",
       "2         Discharge Summary   267681869  2.555255e+08  2015-01-09   \n",
       "3            Progress Notes  1682366001  1.631850e+09  2017-10-03   \n",
       "4            Progress Notes  1853759390  1.807703e+09  2018-02-07   \n",
       "...                     ...         ...           ...         ...   \n",
       "279219       Progress Notes  3960511043  3.943607e+09  2020-04-28   \n",
       "279220       Progress Notes  4585859437  4.574134e+09  2020-09-22   \n",
       "279221       Progress Notes  5203067949  5.224024e+09  2021-01-25   \n",
       "279222       Progress Notes  5673786544  5.670392e+09  2021-04-20   \n",
       "279223       Progress Notes  1939524875  1.895938e+09  2018-04-16   \n",
       "\n",
       "                                                  NoteTXT  \\\n",
       "0       ----------------------------------------------...   \n",
       "1       ----------------------------------------------...   \n",
       "2       ----------------------------------------------...   \n",
       "3       ----------------------------------------------...   \n",
       "4       ----------------------------------------------...   \n",
       "...                                                   ...   \n",
       "279219  ----------------------------------------------...   \n",
       "279220  ----------------------------------------------...   \n",
       "279221  ----------------------------------------------...   \n",
       "279222  ----------------------------------------------...   \n",
       "279223  ----------------------------------------------...   \n",
       "\n",
       "                                               regex_sent  \\\n",
       "0       \"\\\"ession alone in the meta-analysis. We discu...   \n",
       "1       \"\\\" ------- sis over her R bra strap, which wa...   \n",
       "2       \"\\\" ------- l obstruction ASSOCIATED DIAGNOSES...   \n",
       "3       \"\\\" -------  (156 lb) 09/19/17 71.4 kg (157 lb...   \n",
       "4       \"\\\"ut answer. Optho notes from recent outpatie...   \n",
       "...                                                   ...   \n",
       "279219  \"\\\"''she took a break' and wants to discuss wi...   \n",
       "279220  \"\\\"'all of her medications, including aspirin....   \n",
       "279221  \"\\\"'Patient, Chart, daughter Olga Mode of cont...   \n",
       "279222  \"\\\"'Patient, Chart, daughter Olga Mode of cont...   \n",
       "279223  \"\\\"'cyanosis or edema. Neurological exam: Nonf...   \n",
       "\n",
       "                                   regex_match  \\\n",
       "0                               \"['dementia']\"   \n",
       "1             \"['dementia', 'memory', 'moca']\"   \n",
       "2       \"['dementia', 'cognitive impairment']\"   \n",
       "3                  \"['dementia', 'cognition']\"   \n",
       "4                               \"['dementia']\"   \n",
       "...                                        ...   \n",
       "279219                            \"['memory']\"   \n",
       "279220                            \"['memory']\"   \n",
       "279221                         \"['cognition']\"   \n",
       "279222                         \"['cognition']\"   \n",
       "279223                         \"['cognition']\"   \n",
       "\n",
       "                                           regex_location  \n",
       "0                                            [(397, 405)]  \n",
       "1       [(256, 264), (561, 569), (217, 223), (513, 519...  \n",
       "2                    [(180, 188), (627, 635), (398, 418)]  \n",
       "3                                [(512, 520), (294, 303)]  \n",
       "4                                            [(395, 403)]  \n",
       "...                                                   ...  \n",
       "279219                                        [(99, 105)]  \n",
       "279220                                       [(101, 107)]  \n",
       "279221                                       [(100, 109)]  \n",
       "279222                                       [(100, 109)]  \n",
       "279223                                       [(100, 109)]  \n",
       "\n",
       "[279224 rows x 13 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations = []\n",
    "\n",
    "# for i in tqdm(range(len(merged['regex_sent']))):\n",
    "#     r = merged['regex_sent'][i]\n",
    "#     l = []\n",
    "#     for p in p_list:\n",
    "#         for match in re.finditer(p, r):\n",
    "#             l.append(match.group().lower())\n",
    "#             l = list(set(l))\n",
    "#     #print(l)\n",
    "#     merged.append(l)\n",
    "        \n",
    "# merged[\"regex_match\"] = locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for note in tqdm(merged[\"regex_sent\"]):\n",
    "    curr = []\n",
    "    for p in (p_list):\n",
    "        m = list(set(re.findall(p, note)))\n",
    "        m = list(set(map(str.lower, m)))\n",
    "        if (m != []):\n",
    "            curr.append(\"\".join(m))\n",
    "    #print(curr)\n",
    "    #print(l)\n",
    "    l.append(str(curr))\n",
    "\n",
    "merged[\"sequence_level_regex_match\"] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[:1000].to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\nlp_annotator-dev\\app\\load_data\\regex_match_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncating notes to max 131K characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"NoteTXT\"] = matches[\"NoteTXT\"].str[:131000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[\"len\"]=matches[\"NoteTXT\"].str.len()\n",
    "matches[\"len\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches[['PatientID', 'MRN', 'EMPI', 'PatientEncounterID',\n",
    "       'InpatientNoteTypeDSC', 'NoteID', 'NoteCSNID', 'ContactDTS', 'NoteTXT',\n",
    "       'regex_sent', 'regex_match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\nlp_annotator-dev\\app\\load_data\\SLAT_production_7_24.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production.to_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\nlp_annotator-dev\\app\\load_data\\SLAT_production_7_22.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
