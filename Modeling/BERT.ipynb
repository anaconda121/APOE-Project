{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandasgui import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# General\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "from datetime import date\n",
    "import warnings\n",
    "current_date = date.today()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# deep learning libraries\n",
    "import torch\n",
    "import transformers\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna.visualization.matplotlib as oviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available?  No\n"
     ]
    }
   ],
   "source": [
    "# set seeds to make computations deterministic\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# check CUDA availability\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"Is CUDA available? \", \"Yes\" if cuda_available else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logging options\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "always_patterns = pd.read_csv(\"input_optimized.csv\") \n",
    "manual_review = pd.read_csv(r\"C:\\Users\\MIND_DS\\Dropbox (Partners HealthCare)\\NLP\\Tanish\\APOE-SLAT\\Modeling\\test_and_validation.csv\")\n",
    "manual_review = manual_review[['patient_id', 'sequence', 'annotator_label']]\n",
    "always_patterns = always_patterns[['patient_id', 'sequence', 'annotator_label']]\n",
    "df = pd.concat([manual_review, always_patterns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', \n",
    "                                          do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", \n",
    "                                                      num_labels = 3, \n",
    "                                                      output_attentions = False, \n",
    "                                                      output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    input_ids = [] # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    lengths = []  # Record the length of each sequence (after truncating to 512).\n",
    "\n",
    "    # For every sentence...\n",
    "    for sen in df.sequence: \n",
    "        # `encode` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        encoded_sent = tokenizer.encode (\n",
    "                            sen,                     \n",
    "                            add_special_tokens = True, \n",
    "                            pad_to_max_length = True, \n",
    "                            max_length = 1024,\n",
    "                            truncation = True\n",
    "                       )   \n",
    "\n",
    "        # Add the encoded sentence to the list.\n",
    "        input_ids.append(encoded_sent)\n",
    "        # Record the truncated length.\n",
    "        lengths.append(len(encoded_sent))\n",
    "\n",
    "    print('DONE.')\n",
    "    print('{:,} notes sample.'.format(len(input_ids)))\n",
    "    \n",
    "    return input_ids, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE.\n",
      "8,050 notes sample.\n"
     ]
    }
   ],
   "source": [
    "always_input_ids, always_lengths = preprocessing(always_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE.\n",
      "606 notes sample.\n"
     ]
    }
   ],
   "source": [
    "manual_input_ids, manual_lengths = preprocessing(manual_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "always_input_ids = pad_sequences(always_input_ids, maxlen = 1024, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_input_ids = pad_sequences(manual_input_ids, maxlen = 1024, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_masks(input_ids):\n",
    "    # Create attention masks\n",
    "    attention_masks = []\n",
    "    for sent in input_ids: \n",
    "        # Create the attention mask.\n",
    "        #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "        #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]  \n",
    "        # Store the attention mask for this sentence.\n",
    "        attention_masks.append(att_mask)\n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "always_attention_masks = attention_masks(always_input_ids)\n",
    "manual_attention_masks = attention_masks(manual_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(input_ids, attention_mask):\n",
    "    def helper(X, y, X_2, y_2):\n",
    "        # stratiftying on df with sequences that have always pattern matches \n",
    "        y_label = y.to_numpy()\n",
    "        X_train, X_test_valid, y_train, y_test_valid = train_test_split(X, y, random_state = 0, test_size = 0.1, stratify = y_label)\n",
    "\n",
    "        y_test_valid_label = y_test_valid.to_numpy()\n",
    "        X_valid, X_test, y_valid, y_test = train_test_split(X_test_valid, y_test_valid, random_state = 0, test_size = 0.25, stratify = y_test_valid_label)\n",
    "\n",
    "        # stratiftying on df with sequences that don't have always pattern matches\n",
    "        y_label_2 = y_2.to_numpy()\n",
    "        X_train_2, X_test_valid_2, y_train_2, y_test_valid_2 = train_test_split(X_2, y_2, random_state = 0, test_size = 0.6, stratify = y_label_2)\n",
    "\n",
    "        y_test_valid_label_2 = y_test_valid_2.to_numpy()\n",
    "        X_valid_2, X_test_2, y_valid_2, y_test_2 = train_test_split(X_test_valid_2, y_test_valid_2, random_state = 0, test_size = (0.25/0.6), stratify = y_test_valid_label_2)\n",
    "        \n",
    "        # combining\n",
    "        X_train = np.concatenate((X_train, X_train_2), axis = 0)\n",
    "        y_train.append(y_train_2)\n",
    "        prin\n",
    "        X_test = np.concatenate((X_test, X_test_2), axis = 0)\n",
    "        y_test.append(y_test_2)\n",
    "\n",
    "        X_valid = np.concatenate((X_valid, X_valid_2), axis = 0)\n",
    "        y_valid.append(y_valid_2)\n",
    "        \n",
    "        return X_train, y_train, X_valid, y_valid, X_test, y_test \n",
    "        \n",
    "    if (input_ids == True):\n",
    "        # doing split on input_ids\n",
    "        X = always_input_ids\n",
    "        y = always_patterns[\"annotator_label\"]\n",
    "        X_2 = manual_input_ids\n",
    "        y_2 = manual_review[\"annotator_label\"] \n",
    "        \n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test = helper(X, y, X_2, y_2)\n",
    "        return X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "    \n",
    "    elif (attention_mask == True):\n",
    "        # doing split on attention masks\n",
    "        X = always_attention_masks\n",
    "        y = always_patterns[\"annotator_label\"]\n",
    "        X_2 = manual_attention_masks\n",
    "        y_2 = manual_review[\"annotator_label\"]\n",
    "        \n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test = helper(X, y, X_2, y_2)\n",
    "        return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_label, valid_input, valid_label, test_input, test_label = split(True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, _, valid_mask, _, test_mask, _ = split(False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "train_inputs = torch.tensor(train_input)\n",
    "validation_inputs = torch.tensor(valid_input)\n",
    "test_inputs = torch.tensor(test_input)\n",
    "\n",
    "train_labels = torch.tensor(train_label.to_list())\n",
    "validation_labels = torch.tensor(valid_label.to_list())\n",
    "test_labels = torch.tensor(test_label.to_list())\n",
    "\n",
    "train_masks = torch.tensor(train_mask)\n",
    "validation_masks = torch.tensor(valid_mask)\n",
    "test_masks = torch.tensor(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7487, 1024])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7487, 1024])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7245])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-da2466d4cf6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Create the DataLoader for our training set.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain_sampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Size mismatch between tensors\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 4\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:,} negative (no cognitive impairment)'.format(len(df[df[\"annotator_label\"] == 0])))\n",
    "print('{:,} neither (not relevant to cognitive impairment)'.format(len(df[df[\"annotator_label\"] == 1])))\n",
    "print('{:,} positive (cognitive impairment)'.format(len(df[df[\"annotator_label\"] == 2])))\n",
    "\n",
    "print('Min length:    {:,} tokens'.format(min(lengths)))\n",
    "print('Max length:    {:,} tokens'.format(max(lengths)))\n",
    "print('Median length: {:,} tokens'.format(np.median(lengths)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(trial):\n",
    "    # stratify across sequences with and without always pattern matches and class_label (Y, N, NTR)\n",
    "    \n",
    "    # stratifying across sequences with always pattern\n",
    "    X_train, X_other = train_test_split(always_patterns, random_state = 0,test_size = 0.1, stratify = always_patterns[\"annotator_label\"].to_numpy())\n",
    "\n",
    "    X_valid, X_test = train_test_split(X_other, random_state = 0, test_size = 0.25, stratify = X_other[\"annotator_label\"].to_numpy())\n",
    "    \n",
    "    # stratifying across sequences without always pattern\n",
    "    X_train_2, X_other_2 = train_test_split(manual_review, random_state = 0,test_size = 0.6, stratify = manual_review[\"annotator_label\"].to_numpy())\n",
    "\n",
    "    X_valid_2, X_test_2 = train_test_split(X_other_2, random_state = 0, test_size = (0.25/0.6), stratify = X_test_2[\"annotator_label\"].to_numpy())\n",
    "    \n",
    "    # combining to get final train, test, validation splits\n",
    "    X_train = X_train.append(X_train_2)\n",
    "    X_valid = X_valid.append(X_valid_2)\n",
    "    X_test = X_test.append(X_test_2)\n",
    "\n",
    "    return X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial, trial_dir):\n",
    "    # set learning rate\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    # define model name\n",
    "    model_type = \"bert\"\n",
    "    model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "    max_seq_length = 512\n",
    "\n",
    "    model_args = ClassificationArgs (\n",
    "        ## NLP ARGUMENTS\n",
    "        sliding_window = False,\n",
    "        learning_rate = learning_rate, # default 4e-5\n",
    "        adam_epsilon = 1e-8, # default 1e-8\n",
    "        train_batch_size = 8, # default 8\n",
    "        eval_batch_size = 4, # default 8\n",
    "        num_train_epochs = 3,  # default 1 (number of epochs model will be trained for)\n",
    "        do_lower_case = False, # default False\n",
    "        max_seq_length = max_seq_length, # default 128 (maximum sequence length the model will support)\n",
    "\n",
    "        ## TRAINING LOOP\n",
    "        logging_steps = 50, # default 50\n",
    "        manual_seed = 1234, # default None (necessary for reproducible results)\n",
    "        n_gpu = 0, # default 1 (number of GPUs to use)\n",
    "        save_steps = 2000, # default 2000 (save a model checkpoint at every specified number of steps)\n",
    "        output_dir = trial_dir, \n",
    "        overwrite_output_dir = True, # default False (if True, then the trained model will be saved to the ouput_dir and will overwrite existing saved models in the same directory)\n",
    "\n",
    "        ## EVALUATE DURING TRAINING\n",
    "        evaluate_during_training = True, # default False\n",
    "        evaluate_during_training_steps = 2000, # default  2000  \n",
    "        evaluate_during_training_verbose = True, # default False\n",
    "\n",
    "        ## EARLY STOPPING\n",
    "        use_early_stopping = True, # default False\n",
    "        early_stopping_delta = 0, # default 0 (improvement over best_eval_loss necessary to count as a better checkpoint)\n",
    "        early_stopping_metric = \"auc\", # default eval_loss \n",
    "        early_stopping_metric_minimize = True, # default True\n",
    "        early_stopping_patience = 2, # default value 3 (terminate training after these many epochs if there is no improvement in early_stopping_metric then early_stopping_delta)\n",
    "    )\n",
    "\n",
    "    # create the classification model\n",
    "    model = ClassificationModel (\n",
    "        model_type, model_name,\n",
    "        args = model_args,\n",
    "        use_cuda = cuda_available\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = manual_review[\"sequence\"]\n",
    "y_2 = manual_review[\"annotator_label\"]\n",
    "\n",
    "y_label_2 = y_2.to_numpy()\n",
    "X_train_2, X_test_valid_2, y_train_2, y_test_valid_2 = train_test_split(X_2,y_2,random_state=0,test_size=0.6, stratify=y_label_2)\n",
    "\n",
    "y_test_valid_label_2 = y_test_valid_2.to_numpy()\n",
    "X_valid_2, X_test_2, y_valid_2, y_test_2 = train_test_split(X_test_valid_2, y_test_valid_2, random_state=0, test_size=(0.25/0.6), stratify=y_test_valid_label_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
